{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "united-daily",
   "metadata": {},
   "source": [
    "# Medical Transcription Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-magnet",
   "metadata": {},
   "source": [
    "The goal of this project is to develop or find a NLP model that can correctly classify the medical specialties based on the transcription text with significant accuracy. This project was heavily inspired by the existing Kaggle dataset Medical Transcriptions uploaded by Tara Boyle and the website mtsamples.com that has a collection of transcribed medical report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "resistant-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "improving-stream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A 23-year-old white female presents with comp...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Allergic Rhinitis</td>\n",
       "      <td>SUBJECTIVE:,  This 23-year-old white female pr...</td>\n",
       "      <td>allergy / immunology, allergic rhinitis, aller...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 2</td>\n",
       "      <td>PAST MEDICAL HISTORY:, He has difficulty climb...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, weigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 1</td>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: , I have seen ABC ...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, heart...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description      medical_specialty  \\\n",
       "0   A 23-year-old white female presents with comp...   Allergy / Immunology   \n",
       "1           Consult for laparoscopic gastric bypass.             Bariatrics   \n",
       "2           Consult for laparoscopic gastric bypass.             Bariatrics   \n",
       "\n",
       "                                 sample_name  \\\n",
       "0                         Allergic Rhinitis    \n",
       "1   Laparoscopic Gastric Bypass Consult - 2    \n",
       "2   Laparoscopic Gastric Bypass Consult - 1    \n",
       "\n",
       "                                       transcription  \\\n",
       "0  SUBJECTIVE:,  This 23-year-old white female pr...   \n",
       "1  PAST MEDICAL HISTORY:, He has difficulty climb...   \n",
       "2  HISTORY OF PRESENT ILLNESS: , I have seen ABC ...   \n",
       "\n",
       "                                            keywords  \n",
       "0  allergy / immunology, allergic rhinitis, aller...  \n",
       "1  bariatrics, laparoscopic gastric bypass, weigh...  \n",
       "2  bariatrics, laparoscopic gastric bypass, heart...  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"mtsamples.csv\", usecols=[\"description\", \"medical_specialty\", \"sample_name\", \"transcription\", \"keywords\"])\n",
    "data_df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-assault",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "applicable-sperm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4999 entries, 0 to 4998\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   description        4999 non-null   object\n",
      " 1   medical_specialty  4999 non-null   object\n",
      " 2   sample_name        4999 non-null   object\n",
      " 3   transcription      4966 non-null   object\n",
      " 4   keywords           3931 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 195.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "difficult-mobility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4999</td>\n",
       "      <td>4999</td>\n",
       "      <td>4999</td>\n",
       "      <td>4966</td>\n",
       "      <td>3931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2348</td>\n",
       "      <td>40</td>\n",
       "      <td>2377</td>\n",
       "      <td>2357</td>\n",
       "      <td>3849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>An example/template for a routine normal male...</td>\n",
       "      <td>Surgery</td>\n",
       "      <td>Lumbar Discogram</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS: , Low back pain.,POSTO...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>12</td>\n",
       "      <td>1103</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description medical_specialty  \\\n",
       "count                                                4999              4999   \n",
       "unique                                               2348                40   \n",
       "top      An example/template for a routine normal male...           Surgery   \n",
       "freq                                                   12              1103   \n",
       "\n",
       "               sample_name                                      transcription  \\\n",
       "count                 4999                                               4966   \n",
       "unique                2377                                               2357   \n",
       "top      Lumbar Discogram   PREOPERATIVE DIAGNOSIS: , Low back pain.,POSTO...   \n",
       "freq                     5                                                  5   \n",
       "\n",
       "       keywords  \n",
       "count      3931  \n",
       "unique     3849  \n",
       "top              \n",
       "freq         81  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "excess-empty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Surgery                          1103\n",
       " Consult - History and Phy.        516\n",
       " Cardiovascular / Pulmonary        372\n",
       " Orthopedic                        355\n",
       " Radiology                         273\n",
       " General Medicine                  259\n",
       " Gastroenterology                  230\n",
       " Neurology                         223\n",
       " SOAP / Chart / Progress Notes     166\n",
       " Obstetrics / Gynecology           160\n",
       " Urology                           158\n",
       " Discharge Summary                 108\n",
       " ENT - Otolaryngology               98\n",
       " Neurosurgery                       94\n",
       " Hematology - Oncology              90\n",
       " Ophthalmology                      83\n",
       " Nephrology                         81\n",
       " Emergency Room Reports             75\n",
       " Pediatrics - Neonatal              70\n",
       " Pain Management                    62\n",
       " Psychiatry / Psychology            53\n",
       " Office Notes                       51\n",
       " Podiatry                           47\n",
       " Dermatology                        29\n",
       " Dentistry                          27\n",
       " Cosmetic / Plastic Surgery         27\n",
       " Letters                            23\n",
       " Physical Medicine - Rehab          21\n",
       " Sleep Medicine                     20\n",
       " Endocrinology                      19\n",
       " Bariatrics                         18\n",
       " IME-QME-Work Comp etc.             16\n",
       " Chiropractic                       14\n",
       " Rheumatology                       10\n",
       " Diets and Nutritions               10\n",
       " Speech - Language                   9\n",
       " Lab Medicine - Pathology            8\n",
       " Autopsy                             8\n",
       " Allergy / Immunology                7\n",
       " Hospice - Palliative Care           6\n",
       "Name: medical_specialty, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['medical_specialty'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "digital-material",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREOPERATIVE DIAGNOSIS: , Morbid obesity. ,POSTOPERATIVE DIAGNOSIS: , Morbid obesity. ,PROCEDURE:,  Laparoscopic Roux-en-Y gastric bypass, antecolic, antegastric with 25-mm EEA anastamosis, esophagogastroduodenoscopy. ,ANESTHESIA: , General with endotracheal intubation. ,INDICATIONS FOR PROCEDURE: , This is a 50-year-old male who has been overweight for many years and has tried multiple different weight loss diets and programs.  The patient has now begun to have comorbidities related to the obesity.  The patient has attended our bariatric seminar and met with our dietician and psychologist.  The patient has read through our comprehensive handout and understands the risks and benefits of bypass surgery as evidenced by the signing of our consent form.,PROCEDURE IN DETAIL: , The risks and benefits were explained to the patient.  Consent was obtained.  The patient was taken to the operating room and placed supine on the operating room table.  General anesthesia was administered with endotracheal intubation.  A Foley catheter was placed for bladder decompression.  All pressure points were carefully padded, and sequential compression devices were placed on the legs.  The abdomen was prepped and draped in standard, sterile, surgical fashion.  Marcaine was injected into the umbilicus.'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[\"transcription\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "employed-purpose",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2-D STUDY,1. Mild aortic stenosis, widely calcified, minimally restricted.,2. Mild left ventricular hypertrophy but normal systolic function.,3. Moderate biatrial enlargement.,4. Normal right ventricle.,5. Normal appearance of the tricuspid and mitral valves.,6. Normal left ventricle and left ventricular systolic function.,DOPPLER,1. There is 1 to 2+ aortic regurgitation easily seen, but no aortic stenosis.,2. Mild tricuspid regurgitation with only mild increase in right heart pressures, 30-35 mmHg maximum.,SUMMARY,1. Normal left ventricle.,2. Moderate biatrial enlargement.,3. Mild tricuspid regurgitation, but only mild increase in right heart pressures.'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[\"transcription\"][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "drawn-religion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Morbid obesity.  Laparoscopic Roux-en-Y gastric bypass, antecolic, antegastric with 25-mm EEA anastamosis, esophagogastroduodenoscopy.'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[\"description\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "appropriate-impossible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Normal left ventricle, moderate biatrial enlargement, and mild tricuspid regurgitation, but only mild increase in right heart pressures.'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[\"description\"][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "declared-stocks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Laparoscopic Gastric Bypass - 1 '"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[\"sample_name\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "serious-hunter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description          False\n",
       "medical_specialty    False\n",
       "sample_name          False\n",
       "transcription         True\n",
       "keywords              True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.isna().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "continental-irish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description             0\n",
       "medical_specialty       0\n",
       "sample_name             0\n",
       "transcription          33\n",
       "keywords             1068\n",
       "dtype: int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-queensland",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "mediterranean-portugal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4999, 2)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only use two columns \n",
    "\n",
    "data_tr = data_df[[\"medical_specialty\", \"transcription\"]]\n",
    "data_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "mexican-scotland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4966, 2)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows where transcriptions don't have any text \n",
    "\n",
    "data_tr = data_tr.dropna(axis=0)\n",
    "data_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "buried-address",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Urology</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS: , Inguinal hernia.,POS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Urology</td>\n",
       "      <td>PROCEDURE PERFORMED: , Inguinal herniorrhaphy....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Urology</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS:,  Bilateral inguinal h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   medical_specialty                                      transcription\n",
       "95           Urology  PREOPERATIVE DIAGNOSIS: , Inguinal hernia.,POS...\n",
       "96           Urology  PROCEDURE PERFORMED: , Inguinal herniorrhaphy....\n",
       "98           Urology  PREOPERATIVE DIAGNOSIS:,  Bilateral inguinal h..."
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tr[95:98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "amended-meter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Urology</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS: , Inguinal hernia.,POS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Urology</td>\n",
       "      <td>PROCEDURE PERFORMED: , Inguinal herniorrhaphy....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Urology</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS:,  Bilateral inguinal h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   medical_specialty                                      transcription\n",
       "95           Urology  PREOPERATIVE DIAGNOSIS: , Inguinal hernia.,POS...\n",
       "96           Urology  PROCEDURE PERFORMED: , Inguinal herniorrhaphy....\n",
       "97           Urology  PREOPERATIVE DIAGNOSIS:,  Bilateral inguinal h..."
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tr = data_tr.reset_index().drop(\"index\", axis=1)\n",
    "data_tr[95:98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "confident-train",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allergy immunology</td>\n",
       "      <td>this year old white female presents with compl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bariatrics</td>\n",
       "      <td>he has difficulty climbing stairs difficulty w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bariatrics</td>\n",
       "      <td>i have seen today he is a very pleasant gentle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    medical_specialty                                      transcription\n",
       "0  allergy immunology  this year old white female presents with compl...\n",
       "1          bariatrics  he has difficulty climbing stairs difficulty w...\n",
       "2          bariatrics  i have seen today he is a very pleasant gentle..."
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def strip_lr(row):\n",
    "    output = row.strip()\n",
    "    return output\n",
    "\n",
    "def clean_text(row):\n",
    "    sample_text = row\n",
    "    sample_text2 = re.sub(r\"\\.\", \" \", sample_text) # replace any . \n",
    "    sample_text2 = re.sub(r\"[A-Z]{2,}\", \"\", sample_text2) # replace any UPPERCASE words longer than 2 characters\n",
    "    sample_text2 = re.sub(r\"\\d\", \"\", sample_text2) # replace any digit\n",
    "    sample_text2 = re.sub(r\"\\:\", \" \", sample_text2) # replace :\n",
    "    sample_text2 = re.sub(r\",\", \"\", sample_text2) # replace comma\n",
    "    sample_text2 = re.sub(r\"-\", \" \", sample_text2)\n",
    "    sample_text2 = re.sub(r\"_\", \" \", sample_text2)\n",
    "    sample_text2 = re.sub(r\"[\\\\\\/]\", \" \", sample_text2) \n",
    "    sample_text2 = re.sub(r\"\\s{2,}\", \" \", sample_text2) # replace whitespaces longer than 2\n",
    "    sample_text2 = sample_text2.strip() # strip any whitespace on the sides of text\n",
    "    sample_text2 = sample_text2.lower() # make everything lowercase\n",
    "    output = sample_text2\n",
    "    \n",
    "    return output\n",
    "\n",
    "data_tr['medical_specialty'] = data_tr['medical_specialty'].apply(strip_lr)\n",
    "data_tr['medical_specialty'] = data_tr['medical_specialty'].apply(clean_text)\n",
    "data_tr['transcription'] = data_tr['transcription'].apply(clean_text)\n",
    "data_tr.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "empty-skiing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he has difficulty climbing stairs difficulty with airline seats tying shoes used to public seating and lifting objects off the floor he exercises three times a week at home and does cardio he has difficulty walking two blocks or five flights of stairs difficulty with snoring he has muscle and joint pains including knee pain back pain foot and ankle pain and swelling he has gastroesophageal reflux disease includes reconstructive surgery on his right hand years ago he is currently single he has about ten drinks a year he had smoked significantly up until several months ago he now smokes less than three cigarettes a day heart disease in both grandfathers grandmother with stroke and a grandmother with diabetes denies obesity and hypertension in other family members none he is allergic to penicillin he has been going to support groups for seven months with lynn holmberg in greenwich and he is from eastchester new york and he feels that we are the appropriate program he had a poor experience with the greenwich program eating history he is not an emotional eater does not like sweets he likes big portions and carbohydrates he likes chicken and not steak he currently weighs pounds ideal body weight would be pounds he is pounds overweight if he lost % of his excess body weight that would be pounds and he should weigh about negative for head neck heart lungs orthopedic and skin specifically denies chest pain heart attack coronary artery disease congestive heart failure arrhythmia atrial fibrillation pacemaker high cholesterol pulmonary embolism high blood pressure venous insufficiency thrombophlebitis asthma shortness of breath emphysema sleep apnea diabetes leg and foot swelling osteoarthritis rheumatoid arthritis hiatal hernia peptic ulcer disease gallstones infected gallbladder pancreatitis fatty liver hepatitis hemorrhoids rectal bleeding polyps incontinence of stool urinary stress incontinence or cancer denies cellulitis pseudotumor cerebri meningitis or encephalitis he is alert and oriented x cranial nerves are intact afebrile vital signs are stable'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tr['transcription'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "extensive-ordering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surgery                     1088\n",
       "consult history and phy      516\n",
       "cardiovascular pulmonary     371\n",
       "orthopedic                   355\n",
       "radiology                    273\n",
       "general medicine             259\n",
       "gastroenterology             224\n",
       "neurology                    223\n",
       "chart progress notes         166\n",
       "urology                      156\n",
       "obstetrics gynecology        155\n",
       "discharge summary            108\n",
       "otolaryngology                96\n",
       "neurosurgery                  94\n",
       "hematology oncology           90\n",
       "ophthalmology                 83\n",
       "nephrology                    81\n",
       "emergency room reports        75\n",
       "pediatrics neonatal           70\n",
       "pain management               61\n",
       "psychiatry psychology         53\n",
       "office notes                  50\n",
       "podiatry                      47\n",
       "dermatology                   29\n",
       "dentistry                     27\n",
       "cosmetic plastic surgery      27\n",
       "letters                       23\n",
       "physical medicine rehab       21\n",
       "sleep medicine                20\n",
       "endocrinology                 19\n",
       "bariatrics                    18\n",
       "work comp etc                 16\n",
       "chiropractic                  14\n",
       "diets and nutritions          10\n",
       "rheumatology                  10\n",
       "speech language                9\n",
       "autopsy                        8\n",
       "lab medicine pathology         8\n",
       "allergy immunology             7\n",
       "hospice palliative care        6\n",
       "Name: medical_specialty, dtype: int64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tr['medical_specialty'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "dimensional-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "texts = data_tr['transcription']\n",
    "tokenized_texts = [row.split() for row in texts]\n",
    "vocabulary = Counter()\n",
    "\n",
    "for row in tokenized_texts:\n",
    "    vocabulary.update(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "mineral-information",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22116"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "appointed-middle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 149521), ('and', 81921), ('was', 71759), ('of', 56203), ('to', 50468)]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "computational-recruitment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2991"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max([len(row) for row in tokenized_texts])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-mouse",
   "metadata": {},
   "source": [
    "### Split the Data into Train, Validation, Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "sustained-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split: \n",
    "# train set: 70% \n",
    "# val set: 15%\n",
    "# test set: 15% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "miniature-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, train_size=0.7, random_state=42)\n",
    "for train_index, val_test_index in sss.split(data_tr, data_tr['medical_specialty']):\n",
    "    train_set = data_tr.loc[data_tr.index.intersection(train_index)]\n",
    "    val_test_set = data_tr.loc[data_tr.index.intersection(val_test_index)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "fossil-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_set.drop('medical_specialty',axis=1)['transcription']\n",
    "train_y = train_set['medical_specialty'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "athletic-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, train_size=0.5, random_state=42)\n",
    "for val_index, test_index in sss.split(val_test_set, val_test_set['medical_specialty']):\n",
    "    val_set = val_test_set.loc[val_test_set.index.intersection(val_index)]\n",
    "    test_set = val_test_set.loc[val_test_set.index.intersection(test_index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "antique-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = val_set.drop('medical_specialty',axis=1)['transcription']\n",
    "val_y = val_set[\"medical_specialty\"].copy()\n",
    "test_X = test_set.drop('medical_specialty',axis=1)['transcription']\n",
    "test_y = test_set['medical_specialty'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "turkish-trinidad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3476,), (228,), (219,))"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, val_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "billion-latin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       this year old white female presents with compl...\n",
       "1       he has difficulty climbing stairs difficulty w...\n",
       "3       d m left atrial enlargement with left atrial d...\n",
       "6       deformity right breast reconstruction excess s...\n",
       "7       d multiple views of the heart and great vessel...\n",
       "                              ...                        \n",
       "4959    i ligature strangulation a circumferential lig...\n",
       "4960    a year old female presents self referred for t...\n",
       "4962    kawasaki disease kawasaki disease resolving th...\n",
       "4963    this is a year old white female who comes in t...\n",
       "4964    this year old male presents to children's hosp...\n",
       "Name: transcription, Length: 3476, dtype: object"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-basket",
   "metadata": {},
   "source": [
    "### Baseline Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-station",
   "metadata": {},
   "source": [
    "#### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "looking-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_specialties = list(data_tr['medical_specialty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "coordinated-allocation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F-1 score: 0.14473684210526316\n",
      "Macro F-1 score: 0.011146135417980079\n",
      "Weighted F-1 score: 0.22553957709808506\n"
     ]
    }
   ],
   "source": [
    "# Validation Set\n",
    "random_pred = np.random.choice(medical_specialties, val_set.shape[0])\n",
    "\n",
    "print(\"Micro F-1 score:\", f1_score(val_y, random_pred, average=\"micro\"))\n",
    "print(\"Macro F-1 score:\", f1_score(val_y, random_pred, average=\"macro\"))\n",
    "print(\"Weighted F-1 score:\", f1_score(val_y, random_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "backed-fighter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F-1 score: 0.182648401826484\n",
      "Macro F-1 score: 0.016040316922849972\n",
      "Weighted F-1 score: 0.2788184885588703\n"
     ]
    }
   ],
   "source": [
    "# Test Set\n",
    "random_pred = np.random.choice(medical_specialties, test_set.shape[0])\n",
    "\n",
    "print(\"Micro F-1 score:\", f1_score(test_y, random_pred, average=\"micro\"))\n",
    "print(\"Macro F-1 score:\", f1_score(test_y, random_pred, average=\"macro\"))\n",
    "print(\"Weighted F-1 score:\", f1_score(test_y, random_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-carolina",
   "metadata": {},
   "source": [
    "#### Most common/majority "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "dynamic-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_label = data_tr['medical_specialty'].value_counts().sort_values(ascending=False).index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "frank-center",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F-1 score: 0.7017543859649122\n",
      "Macro F-1 score: 0.09163802978235967\n",
      "Weighted F-1 score: 0.5787665038885874\n"
     ]
    }
   ],
   "source": [
    "# Validation Set\n",
    "majority_prediction = [majority_label]*val_set.shape[0]\n",
    "print(\"Micro F-1 score:\", f1_score(val_y, majority_prediction, average=\"micro\"))\n",
    "print(\"Macro F-1 score:\", f1_score(val_y, majority_prediction, average=\"macro\"))\n",
    "print(\"Weighted F-1 score:\", f1_score(val_y, majority_prediction, average=\"weighted\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "guided-audio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F-1 score: 0.7579908675799086\n",
      "Macro F-1 score: 0.08623376623376623\n",
      "Weighted F-1 score: 0.653644072822155\n"
     ]
    }
   ],
   "source": [
    "# Test Set\n",
    "majority_prediction = [majority_label]*test_set.shape[0]\n",
    "print(\"Micro F-1 score:\", f1_score(test_y, majority_prediction, average=\"micro\"))\n",
    "print(\"Macro F-1 score:\", f1_score(test_y, majority_prediction, average=\"macro\"))\n",
    "print(\"Weighted F-1 score:\", f1_score(test_y, majority_prediction, average=\"weighted\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-authorization",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "postal-syracuse",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "demonstrated-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "\n",
    "train_X_processed = vectorizer.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "alternate-samba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abdomen',\n",
       " 'abdominal',\n",
       " 'able',\n",
       " 'abnormal',\n",
       " 'abnormalities',\n",
       " 'abscess',\n",
       " 'abuse',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'achieved',\n",
       " 'active',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actually',\n",
       " 'acute',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'adenopathy',\n",
       " 'adequate',\n",
       " 'adhesions',\n",
       " 'administered',\n",
       " 'admission',\n",
       " 'admitted',\n",
       " 'advanced',\n",
       " 'age',\n",
       " 'ago',\n",
       " 'air',\n",
       " 'airway',\n",
       " 'alcohol',\n",
       " 'alert',\n",
       " 'allergies',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'alternatives',\n",
       " 'amounts',\n",
       " 'anastomosis',\n",
       " 'anemia',\n",
       " 'anesthesia',\n",
       " 'anesthetic',\n",
       " 'ankle',\n",
       " 'anterior',\n",
       " 'anteriorly',\n",
       " 'antibiotic',\n",
       " 'antibiotics',\n",
       " 'anxiety',\n",
       " 'aorta',\n",
       " 'aortic',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'applied',\n",
       " 'appreciated',\n",
       " 'appropriate',\n",
       " 'approximated',\n",
       " 'approximately',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'arm',\n",
       " 'arteries',\n",
       " 'artery',\n",
       " 'arthritis',\n",
       " 'asked',\n",
       " 'aspect',\n",
       " 'aspiration',\n",
       " 'aspirin',\n",
       " 'associated',\n",
       " 'asthma',\n",
       " 'atraumatic',\n",
       " 'atrial',\n",
       " 'attention',\n",
       " 'auscultation',\n",
       " 'avoid',\n",
       " 'away',\n",
       " 'axillary',\n",
       " 'baby',\n",
       " 'balloon',\n",
       " 'base',\n",
       " 'based',\n",
       " 'bed',\n",
       " 'began',\n",
       " 'benefits',\n",
       " 'benign',\n",
       " 'betadine',\n",
       " 'better',\n",
       " 'bilateral',\n",
       " 'bilaterally',\n",
       " 'biopsies',\n",
       " 'biopsy',\n",
       " 'bipolar',\n",
       " 'bit',\n",
       " 'bladder',\n",
       " 'blade',\n",
       " 'bleeding',\n",
       " 'block',\n",
       " 'blood',\n",
       " 'blunt',\n",
       " 'body',\n",
       " 'bone',\n",
       " 'bony',\n",
       " 'bovie',\n",
       " 'bowel',\n",
       " 'brain',\n",
       " 'branch',\n",
       " 'breast',\n",
       " 'breath',\n",
       " 'breathing',\n",
       " 'brought',\n",
       " 'bruits',\n",
       " 'bypass',\n",
       " 'calcium',\n",
       " 'came',\n",
       " 'canal',\n",
       " 'cancer',\n",
       " 'cannula',\n",
       " 'capsular',\n",
       " 'capsule',\n",
       " 'carcinoma',\n",
       " 'cardiac',\n",
       " 'care',\n",
       " 'carefully',\n",
       " 'carotid',\n",
       " 'carpal',\n",
       " 'carried',\n",
       " 'cartilage',\n",
       " 'case',\n",
       " 'catheter',\n",
       " 'catheterization',\n",
       " 'caucasian',\n",
       " 'cautery',\n",
       " 'cavity',\n",
       " 'cc',\n",
       " 'cell',\n",
       " 'cells',\n",
       " 'center',\n",
       " 'central',\n",
       " 'cervical',\n",
       " 'cervix',\n",
       " 'chamber',\n",
       " 'change',\n",
       " 'changes',\n",
       " 'chart',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'chest',\n",
       " 'child',\n",
       " 'children',\n",
       " 'chills',\n",
       " 'chromic',\n",
       " 'chronic',\n",
       " 'circumflex',\n",
       " 'clamp',\n",
       " 'clamped',\n",
       " 'clear',\n",
       " 'clinic',\n",
       " 'clinical',\n",
       " 'clock',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closure',\n",
       " 'clubbing',\n",
       " 'cm',\n",
       " 'colon',\n",
       " 'colonoscopy',\n",
       " 'common',\n",
       " 'complaints',\n",
       " 'complete',\n",
       " 'completed',\n",
       " 'completely',\n",
       " 'completion',\n",
       " 'complex',\n",
       " 'complications',\n",
       " 'component',\n",
       " 'compression',\n",
       " 'condition',\n",
       " 'confirmed',\n",
       " 'consent',\n",
       " 'consistent',\n",
       " 'consultation',\n",
       " 'contact',\n",
       " 'continue',\n",
       " 'continued',\n",
       " 'continues',\n",
       " 'continuous',\n",
       " 'contrast',\n",
       " 'control',\n",
       " 'controlled',\n",
       " 'copious',\n",
       " 'copiously',\n",
       " 'cord',\n",
       " 'coronary',\n",
       " 'correct',\n",
       " 'cough',\n",
       " 'coumadin',\n",
       " 'count',\n",
       " 'counts',\n",
       " 'course',\n",
       " 'cranial',\n",
       " 'created',\n",
       " 'creatinine',\n",
       " 'cuff',\n",
       " 'culture',\n",
       " 'cultures',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'cut',\n",
       " 'cyanosis',\n",
       " 'cyst',\n",
       " 'cystic',\n",
       " 'daily',\n",
       " 'daughter',\n",
       " 'day',\n",
       " 'days',\n",
       " 'decided',\n",
       " 'decompression',\n",
       " 'decreased',\n",
       " 'deep',\n",
       " 'defect',\n",
       " 'deformity',\n",
       " 'degenerative',\n",
       " 'degree',\n",
       " 'degrees',\n",
       " 'delivered',\n",
       " 'delivery',\n",
       " 'demonstrated',\n",
       " 'denied',\n",
       " 'denies',\n",
       " 'department',\n",
       " 'depression',\n",
       " 'descending',\n",
       " 'described',\n",
       " 'developed',\n",
       " 'device',\n",
       " 'diabetes',\n",
       " 'diagnosed',\n",
       " 'diagnosis',\n",
       " 'diameter',\n",
       " 'diarrhea',\n",
       " 'did',\n",
       " 'died',\n",
       " 'diet',\n",
       " 'difficult',\n",
       " 'difficulty',\n",
       " 'diffuse',\n",
       " 'dilated',\n",
       " 'direct',\n",
       " 'directed',\n",
       " 'disc',\n",
       " 'discharge',\n",
       " 'discharged',\n",
       " 'discomfort',\n",
       " 'discussed',\n",
       " 'disease',\n",
       " 'disk',\n",
       " 'disorder',\n",
       " 'dissected',\n",
       " 'dissection',\n",
       " 'distal',\n",
       " 'distally',\n",
       " 'distress',\n",
       " 'divided',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'dorsal',\n",
       " 'dose',\n",
       " 'double',\n",
       " 'dr',\n",
       " 'drain',\n",
       " 'drainage',\n",
       " 'draped',\n",
       " 'dressing',\n",
       " 'drill',\n",
       " 'drug',\n",
       " 'dry',\n",
       " 'duct',\n",
       " 'dura',\n",
       " 'ear',\n",
       " 'easily',\n",
       " 'echocardiogram',\n",
       " 'edema',\n",
       " 'edges',\n",
       " 'effusion',\n",
       " 'ejection',\n",
       " 'electrocautery',\n",
       " 'elevated',\n",
       " 'emergency',\n",
       " 'end',\n",
       " 'endotracheal',\n",
       " 'enlarged',\n",
       " 'entered',\n",
       " 'entire',\n",
       " 'epidural',\n",
       " 'epinephrine',\n",
       " 'episode',\n",
       " 'episodes',\n",
       " 'equal',\n",
       " 'erythema',\n",
       " 'esophagus',\n",
       " 'estimated',\n",
       " 'evaluated',\n",
       " 'evaluation',\n",
       " 'evidence',\n",
       " 'exam',\n",
       " 'examination',\n",
       " 'examined',\n",
       " 'excellent',\n",
       " 'excised',\n",
       " 'excision',\n",
       " 'explained',\n",
       " 'exposed',\n",
       " 'exposure',\n",
       " 'extended',\n",
       " 'extending',\n",
       " 'extension',\n",
       " 'extensive',\n",
       " 'extensor',\n",
       " 'external',\n",
       " 'extremities',\n",
       " 'extremity',\n",
       " 'extubated',\n",
       " 'eye',\n",
       " 'eyes',\n",
       " 'face',\n",
       " 'facial',\n",
       " 'failure',\n",
       " 'fall',\n",
       " 'family',\n",
       " 'fascia',\n",
       " 'fashion',\n",
       " 'fat',\n",
       " 'father',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'feels',\n",
       " 'feet',\n",
       " 'felt',\n",
       " 'female',\n",
       " 'femoral',\n",
       " 'fever',\n",
       " 'fevers',\n",
       " 'fibrillation',\n",
       " 'field',\n",
       " 'fifth',\n",
       " 'final',\n",
       " 'findings',\n",
       " 'finger',\n",
       " 'fixation',\n",
       " 'flap',\n",
       " 'flexion',\n",
       " 'flexor',\n",
       " 'floor',\n",
       " 'flow',\n",
       " 'fluid',\n",
       " 'fluoroscopy',\n",
       " 'flushed',\n",
       " 'focal',\n",
       " 'foley',\n",
       " 'follow',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'followup',\n",
       " 'foot',\n",
       " 'foramen',\n",
       " 'forceps',\n",
       " 'foreign',\n",
       " 'fracture',\n",
       " 'free',\n",
       " 'french',\n",
       " 'frontal',\n",
       " 'function',\n",
       " 'fusion',\n",
       " 'gait',\n",
       " 'gallbladder',\n",
       " 'gastric',\n",
       " 'gauge',\n",
       " 'general',\n",
       " 'gentleman',\n",
       " 'given',\n",
       " 'glucose',\n",
       " 'going',\n",
       " 'good',\n",
       " 'grade',\n",
       " 'graft',\n",
       " 'grasped',\n",
       " 'great',\n",
       " 'greater',\n",
       " 'gross',\n",
       " 'grossly',\n",
       " 'guide',\n",
       " 'guidewire',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'having',\n",
       " 'head',\n",
       " 'headache',\n",
       " 'headaches',\n",
       " 'health',\n",
       " 'healthy',\n",
       " 'hearing',\n",
       " 'heart',\n",
       " 'height',\n",
       " 'help',\n",
       " 'hematocrit',\n",
       " 'hematoma',\n",
       " 'hemoglobin',\n",
       " 'hemostasis',\n",
       " 'hernia',\n",
       " 'high',\n",
       " 'hip',\n",
       " 'history',\n",
       " 'home',\n",
       " 'hospital',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'husband',\n",
       " 'hypertension',\n",
       " 'identified',\n",
       " 'iliac',\n",
       " 'images',\n",
       " 'immediately',\n",
       " 'improved',\n",
       " 'improvement',\n",
       " 'inch',\n",
       " 'incised',\n",
       " 'incision',\n",
       " 'incisions',\n",
       " 'include',\n",
       " 'including',\n",
       " 'increase',\n",
       " 'increased',\n",
       " 'increasing',\n",
       " 'infection',\n",
       " 'inferior',\n",
       " 'inferiorly',\n",
       " 'inflated',\n",
       " 'information',\n",
       " 'informed',\n",
       " 'inguinal',\n",
       " 'initial',\n",
       " 'initially',\n",
       " 'injected',\n",
       " 'injection',\n",
       " 'injury',\n",
       " 'inserted',\n",
       " 'insertion',\n",
       " 'inspected',\n",
       " 'instructed',\n",
       " 'insulin',\n",
       " 'intact',\n",
       " 'internal',\n",
       " 'interrupted',\n",
       " 'intervention',\n",
       " 'intraoperative',\n",
       " 'intravenous',\n",
       " 'introduced',\n",
       " 'involving',\n",
       " 'irrigated',\n",
       " 'irrigation',\n",
       " 'issues',\n",
       " 'joint',\n",
       " 'joints',\n",
       " 'junction',\n",
       " 'just',\n",
       " 'kidney',\n",
       " 'knee',\n",
       " 'knife',\n",
       " 'known',\n",
       " 'laparoscopic',\n",
       " 'large',\n",
       " 'later',\n",
       " 'lateral',\n",
       " 'laterally',\n",
       " 'layer',\n",
       " 'layers',\n",
       " 'lead',\n",
       " 'left',\n",
       " 'leg',\n",
       " 'length',\n",
       " 'lens',\n",
       " 'lesion',\n",
       " 'lesions',\n",
       " 'level',\n",
       " 'levels',\n",
       " 'lid',\n",
       " 'lidocaine',\n",
       " 'ligament',\n",
       " 'ligated',\n",
       " 'light',\n",
       " 'like',\n",
       " 'likely',\n",
       " 'limited',\n",
       " 'limits',\n",
       " 'line',\n",
       " 'little',\n",
       " 'liver',\n",
       " 'lives',\n",
       " 'lobe',\n",
       " 'local',\n",
       " 'long',\n",
       " 'longus',\n",
       " 'loss',\n",
       " 'low',\n",
       " 'lower',\n",
       " 'lumbar',\n",
       " 'lumen',\n",
       " 'lung',\n",
       " 'lungs',\n",
       " 'lymph',\n",
       " 'lymphadenopathy',\n",
       " 'main',\n",
       " 'make',\n",
       " 'male',\n",
       " 'management',\n",
       " 'manner',\n",
       " 'marcaine',\n",
       " 'marked',\n",
       " 'married',\n",
       " 'mass',\n",
       " 'masses',\n",
       " 'material',\n",
       " 'mcg',\n",
       " 'measures',\n",
       " 'measuring',\n",
       " 'medial',\n",
       " 'medially',\n",
       " 'medical',\n",
       " 'medication',\n",
       " 'medications',\n",
       " 'mellitus',\n",
       " 'membranes',\n",
       " 'memory',\n",
       " 'mentioned',\n",
       " 'metatarsal',\n",
       " 'mg',\n",
       " 'mid',\n",
       " 'middle',\n",
       " 'midline',\n",
       " 'mild',\n",
       " 'mildly',\n",
       " 'minimal',\n",
       " 'minute',\n",
       " 'minutes',\n",
       " 'ml',\n",
       " 'mm',\n",
       " 'mmhg',\n",
       " 'moderate',\n",
       " 'moist',\n",
       " 'mom',\n",
       " 'monitoring',\n",
       " 'monocryl',\n",
       " 'month',\n",
       " 'months',\n",
       " 'morning',\n",
       " 'mother',\n",
       " 'motion',\n",
       " 'motor',\n",
       " 'mouth',\n",
       " 'movement',\n",
       " 'movements',\n",
       " 'mr',\n",
       " 'mucosa',\n",
       " 'multiple',\n",
       " 'murmur',\n",
       " 'murmurs',\n",
       " 'muscle',\n",
       " 'muscles',\n",
       " 'myocardial',\n",
       " 'nasal',\n",
       " 'nature',\n",
       " 'nausea',\n",
       " 'near',\n",
       " 'neck',\n",
       " 'need',\n",
       " 'needed',\n",
       " 'needle',\n",
       " 'needs',\n",
       " 'negative',\n",
       " 'nerve',\n",
       " 'nerves',\n",
       " 'neurologic',\n",
       " 'neurological',\n",
       " 'new',\n",
       " 'night',\n",
       " 'node',\n",
       " 'nodes',\n",
       " 'non',\n",
       " 'nondistended',\n",
       " 'nontender',\n",
       " 'normal',\n",
       " 'normocephalic',\n",
       " 'nose',\n",
       " 'note',\n",
       " 'noted',\n",
       " 'nourished',\n",
       " 'number',\n",
       " 'numbness',\n",
       " 'nylon',\n",
       " 'oblique',\n",
       " 'obstruction',\n",
       " 'obstructive',\n",
       " 'obtained',\n",
       " 'obvious',\n",
       " 'occasional',\n",
       " 'office',\n",
       " 'old',\n",
       " 'onset',\n",
       " 'open',\n",
       " 'opened',\n",
       " 'operating',\n",
       " 'operative',\n",
       " 'options',\n",
       " 'oral',\n",
       " 'order',\n",
       " 'oriented',\n",
       " 'oropharynx',\n",
       " 'osteotomy',\n",
       " 'outpatient',\n",
       " 'overall',\n",
       " 'oxygen',\n",
       " 'pacemaker',\n",
       " 'pain',\n",
       " 'palpable',\n",
       " 'palpation',\n",
       " 'parents',\n",
       " 'partial',\n",
       " 'passed',\n",
       " 'past',\n",
       " 'patent',\n",
       " 'pathology',\n",
       " 'patient',\n",
       " 'pedicle',\n",
       " 'pelvic',\n",
       " 'pelvis',\n",
       " 'perform',\n",
       " 'performed',\n",
       " 'period',\n",
       " 'peripheral',\n",
       " 'peritoneum',\n",
       " 'phalanx',\n",
       " 'physical',\n",
       " 'physician',\n",
       " 'place',\n",
       " 'placed',\n",
       " 'placement',\n",
       " 'plain',\n",
       " 'plan',\n",
       " 'plane',\n",
       " 'plantar',\n",
       " 'plate',\n",
       " 'pleasant',\n",
       " 'pleural',\n",
       " 'pneumonia',\n",
       " 'point',\n",
       " 'poor',\n",
       " 'port',\n",
       " 'portion',\n",
       " 'position',\n",
       " 'positioned',\n",
       " 'positive',\n",
       " 'possible',\n",
       " 'post',\n",
       " 'posterior',\n",
       " 'posteriorly',\n",
       " 'postoperative',\n",
       " 'potassium',\n",
       " 'pounds',\n",
       " 'pregnancy',\n",
       " 'preoperative',\n",
       " 'prepped',\n",
       " 'prescription',\n",
       " 'present',\n",
       " 'presentation',\n",
       " 'presented',\n",
       " 'presents',\n",
       " 'pressure',\n",
       " 'previous',\n",
       " 'previously',\n",
       " 'primary',\n",
       " 'prior',\n",
       " 'probably',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'procedure',\n",
       " 'proceed',\n",
       " 'process',\n",
       " 'prolene',\n",
       " 'prostate',\n",
       " 'protein',\n",
       " 'provided',\n",
       " 'proximal',\n",
       " 'proximally',\n",
       " 'pulmonary',\n",
       " 'pulse',\n",
       " 'pulses',\n",
       " 'pupils',\n",
       " 'quadrant',\n",
       " 'questions',\n",
       " 'quite',\n",
       " 'radial',\n",
       " 'radiation',\n",
       " 'range',\n",
       " 'rash',\n",
       " 'rate',\n",
       " 'ray',\n",
       " 'rays',\n",
       " 'reactive',\n",
       " 'reapproximated',\n",
       " 'received',\n",
       " 'recent',\n",
       " 'recently',\n",
       " 'recommended',\n",
       " 'recovery',\n",
       " 'rectal',\n",
       " 'rectum',\n",
       " 'rectus',\n",
       " 'recurrent',\n",
       " 'red',\n",
       " 'reduction',\n",
       " 'referred',\n",
       " 'reflected',\n",
       " 'reflexes',\n",
       " 'reflux',\n",
       " 'regarding',\n",
       " 'region',\n",
       " 'regular',\n",
       " 'related',\n",
       " 'release',\n",
       " 'released',\n",
       " 'remained',\n",
       " 'remaining',\n",
       " 'removal',\n",
       " 'remove',\n",
       " 'removed',\n",
       " 'renal',\n",
       " 'repair',\n",
       " 'repeat',\n",
       " 'report',\n",
       " 'reported',\n",
       " 'reports',\n",
       " 'resected',\n",
       " 'resection',\n",
       " 'residual',\n",
       " 'resolved',\n",
       " 'respirations',\n",
       " 'respiratory',\n",
       " 'response',\n",
       " 'rest',\n",
       " 'result',\n",
       " 'results',\n",
       " 'retracted',\n",
       " 'return',\n",
       " 'returned',\n",
       " 'revealed',\n",
       " 'reveals',\n",
       " 'review',\n",
       " 'reviewed',\n",
       " 'rhythm',\n",
       " 'right',\n",
       " 'ring',\n",
       " 'risk',\n",
       " 'risks',\n",
       " 'room',\n",
       " 'root',\n",
       " 'round',\n",
       " 'routine',\n",
       " 'rule',\n",
       " 'running',\n",
       " 'sac',\n",
       " 'said',\n",
       " 'saline',\n",
       " 'satisfactory',\n",
       " 'saturation',\n",
       " 'saw',\n",
       " 'scalpel',\n",
       " 'scan',\n",
       " 'scar',\n",
       " 'scheduled',\n",
       " 'school',\n",
       " 'scissors',\n",
       " 'scope',\n",
       " 'screw',\n",
       " 'screws',\n",
       " 'second',\n",
       " 'secondary',\n",
       " 'section',\n",
       " 'secured',\n",
       " 'sedation',\n",
       " 'seen',\n",
       " 'segment',\n",
       " 'seizure',\n",
       " 'self',\n",
       " 'sensation',\n",
       " 'sensory',\n",
       " 'sent',\n",
       " 'septum',\n",
       " 'severe',\n",
       " 'sharp',\n",
       " 'sheath',\n",
       " 'short',\n",
       " 'shortness',\n",
       " 'shoulder',\n",
       " 'showed',\n",
       " 'shows',\n",
       " 'shunt',\n",
       " 'sided',\n",
       " 'sign',\n",
       " 'significant',\n",
       " 'signs',\n",
       " 'silk',\n",
       " 'similar',\n",
       " 'simple',\n",
       " 'single',\n",
       " 'sinus',\n",
       " 'site',\n",
       " 'sites',\n",
       " 'size',\n",
       " 'skin',\n",
       " 'sleep',\n",
       " 'slightly',\n",
       " 'small',\n",
       " 'smoking',\n",
       " 'sodium',\n",
       " 'soft',\n",
       " 'solution',\n",
       " 'somewhat',\n",
       " 'sounds',\n",
       " 'space',\n",
       " 'specimen',\n",
       " 'speech',\n",
       " 'spinal',\n",
       " 'spine',\n",
       " 'sponge',\n",
       " 'stable',\n",
       " 'stage',\n",
       " 'standard',\n",
       " 'staples',\n",
       " 'started',\n",
       " 'state',\n",
       " 'stated',\n",
       " 'states',\n",
       " 'status',\n",
       " 'stenosis',\n",
       " 'stent',\n",
       " 'steri',\n",
       " 'sterile',\n",
       " 'stitch',\n",
       " 'stomach',\n",
       " 'stool',\n",
       " 'straight',\n",
       " 'strength',\n",
       " 'stress',\n",
       " 'strips',\n",
       " 'stroke',\n",
       " 'structures',\n",
       " 'studies',\n",
       " 'study',\n",
       " 'subcutaneous',\n",
       " 'subcuticular',\n",
       " 'subsequently',\n",
       " 'suction',\n",
       " 'suctioned',\n",
       " 'suite',\n",
       " 'superficial',\n",
       " 'superior',\n",
       " 'superiorly',\n",
       " 'supine',\n",
       " 'supple',\n",
       " 'sure',\n",
       " 'surface',\n",
       " 'surgery',\n",
       " 'surgical',\n",
       " 'suture',\n",
       " 'sutured',\n",
       " 'sutures',\n",
       " 'swelling',\n",
       " 'symmetric',\n",
       " 'symptoms',\n",
       " 'syndrome',\n",
       " 'systems',\n",
       " 'systolic',\n",
       " 'table',\n",
       " 'taken',\n",
       " 'taking',\n",
       " 'tear',\n",
       " 'technique',\n",
       " 'teeth',\n",
       " 'temperature',\n",
       " 'temporal',\n",
       " 'tenderness',\n",
       " 'tendon',\n",
       " 'term',\n",
       " 'test',\n",
       " 'testing',\n",
       " 'th',\n",
       " 'therapy',\n",
       " 'thigh',\n",
       " 'think',\n",
       " 'thought',\n",
       " 'throat',\n",
       " 'thyroid',\n",
       " 'tibial',\n",
       " 'tied',\n",
       " 'time',\n",
       " 'times',\n",
       " 'tip',\n",
       " 'tissue',\n",
       " 'tissues',\n",
       " 'tobacco',\n",
       " 'today',\n",
       " 'toe',\n",
       " 'told',\n",
       " 'tolerated',\n",
       " 'tone',\n",
       " 'tongue',\n",
       " 'tooth',\n",
       " 'total',\n",
       " 'tourniquet',\n",
       " 'trachea',\n",
       " 'tract',\n",
       " 'transected',\n",
       " 'transferred',\n",
       " 'transverse',\n",
       " 'trauma',\n",
       " 'treated',\n",
       " 'treatment',\n",
       " 'trial',\n",
       " 'trocar',\n",
       " 'tube',\n",
       " 'tubes',\n",
       " 'tumor',\n",
       " 'tunnel',\n",
       " 'turned',\n",
       " 'twice',\n",
       " 'tylenol',\n",
       " 'type',\n",
       " 'ulnar',\n",
       " 'ultrasound',\n",
       " 'unable',\n",
       " 'underlying',\n",
       " 'underwent',\n",
       " 'unit',\n",
       " 'units',\n",
       " 'unknown',\n",
       " 'unremarkable',\n",
       " 'upper',\n",
       " 'urinary',\n",
       " 'urine',\n",
       " 'use',\n",
       " 'used',\n",
       " 'using',\n",
       " 'usual',\n",
       " 'uterine',\n",
       " 'uterus',\n",
       " 'utilized',\n",
       " 'utilizing',\n",
       " 'vaginal',\n",
       " 'valve',\n",
       " 'vascular',\n",
       " 'vein',\n",
       " 'venous',\n",
       " 'ventricle',\n",
       " 'ventricular',\n",
       " 'versus',\n",
       " 'vertebral',\n",
       " 'vessel',\n",
       " 'vessels',\n",
       " 'vicryl',\n",
       " 'view',\n",
       " 'vision',\n",
       " 'visit',\n",
       " 'visual',\n",
       " 'visualization',\n",
       " 'visualized',\n",
       " 'vital',\n",
       " 'vitamin',\n",
       " 'vomiting',\n",
       " 'wall',\n",
       " 'warm',\n",
       " 'way',\n",
       " 'weakness',\n",
       " 'week',\n",
       " 'weeks',\n",
       " 'weight',\n",
       " 'went',\n",
       " 'white',\n",
       " 'wife',\n",
       " 'wire',\n",
       " 'withdrawn',\n",
       " 'woman',\n",
       " 'work',\n",
       " 'workup',\n",
       " 'worse',\n",
       " 'worsening',\n",
       " 'wound',\n",
       " 'wrist',\n",
       " 'year',\n",
       " 'years']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "mineral-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X_processed = vectorizer.transform(val_X)\n",
    "test_X_processed = vectorizer.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "jewish-granny",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': 998,\n",
       " 'old': 607,\n",
       " 'white': 987,\n",
       " 'female': 339,\n",
       " 'presents': 676,\n",
       " 'allergies': 30,\n",
       " 'used': 951,\n",
       " 'worse': 994,\n",
       " 'past': 629,\n",
       " 'short': 801,\n",
       " 'time': 905,\n",
       " 'began': 83,\n",
       " 'using': 952,\n",
       " 'weeks': 984,\n",
       " 'ago': 25,\n",
       " 'does': 264,\n",
       " 'appear': 49,\n",
       " 'prescription': 672,\n",
       " 'nasal': 570,\n",
       " 'asthma': 70,\n",
       " 'daily': 212,\n",
       " 'medication': 529,\n",
       " 'think': 899,\n",
       " 'currently': 207,\n",
       " 'known': 469,\n",
       " 'weight': 985,\n",
       " 'pounds': 668,\n",
       " 'blood': 98,\n",
       " 'pressure': 677,\n",
       " 'throat': 901,\n",
       " 'mildly': 541,\n",
       " 'mucosa': 563,\n",
       " 'clear': 156,\n",
       " 'drainage': 271,\n",
       " 'seen': 790,\n",
       " 'neck': 574,\n",
       " 'supple': 869,\n",
       " 'adenopathy': 17,\n",
       " 'lungs': 509,\n",
       " 'use': 950,\n",
       " 'given': 380,\n",
       " 'difficulty': 245,\n",
       " 'floor': 353,\n",
       " 'times': 906,\n",
       " 'week': 983,\n",
       " 'home': 413,\n",
       " 'muscle': 567,\n",
       " 'joint': 462,\n",
       " 'including': 430,\n",
       " 'knee': 467,\n",
       " 'pain': 623,\n",
       " 'foot': 364,\n",
       " 'ankle': 39,\n",
       " 'swelling': 877,\n",
       " 'reflux': 724,\n",
       " 'disease': 255,\n",
       " 'surgery': 872,\n",
       " 'right': 760,\n",
       " 'hand': 394,\n",
       " 'years': 999,\n",
       " 'single': 814,\n",
       " 'months': 554,\n",
       " 'day': 214,\n",
       " 'heart': 402,\n",
       " 'stroke': 855,\n",
       " 'diabetes': 236,\n",
       " 'denies': 229,\n",
       " 'hypertension': 418,\n",
       " 'family': 329,\n",
       " 'going': 382,\n",
       " 'new': 584,\n",
       " 'feels': 336,\n",
       " 'appropriate': 56,\n",
       " 'poor': 656,\n",
       " 'history': 412,\n",
       " 'like': 491,\n",
       " 'body': 100,\n",
       " 'negative': 579,\n",
       " 'head': 396,\n",
       " 'skin': 819,\n",
       " 'chest': 147,\n",
       " 'coronary': 193,\n",
       " 'artery': 63,\n",
       " 'failure': 327,\n",
       " 'atrial': 72,\n",
       " 'fibrillation': 343,\n",
       " 'pacemaker': 622,\n",
       " 'high': 410,\n",
       " 'pulmonary': 694,\n",
       " 'venous': 962,\n",
       " 'shortness': 802,\n",
       " 'breath': 108,\n",
       " 'sleep': 820,\n",
       " 'leg': 479,\n",
       " 'arthritis': 64,\n",
       " 'hernia': 409,\n",
       " 'gallbladder': 375,\n",
       " 'liver': 497,\n",
       " 'rectal': 715,\n",
       " 'bleeding': 96,\n",
       " 'stool': 850,\n",
       " 'urinary': 948,\n",
       " 'stress': 853,\n",
       " 'cancer': 116,\n",
       " 'alert': 29,\n",
       " 'oriented': 616,\n",
       " 'cranial': 200,\n",
       " 'nerves': 581,\n",
       " 'intact': 451,\n",
       " 'vital': 976,\n",
       " 'signs': 810,\n",
       " 'stable': 835,\n",
       " 'left': 478,\n",
       " 'diameter': 239,\n",
       " 'cm': 164,\n",
       " 'normal': 591,\n",
       " 'size': 818,\n",
       " 'ventricle': 963,\n",
       " 'systolic': 882,\n",
       " 'function': 372,\n",
       " 'ventricular': 964,\n",
       " 'ejection': 285,\n",
       " 'effusion': 284,\n",
       " 'aortic': 46,\n",
       " 'valve': 959,\n",
       " 'mmhg': 547,\n",
       " 'mild': 540,\n",
       " 'deformity': 221,\n",
       " 'breast': 107,\n",
       " 'soft': 825,\n",
       " 'tissue': 908,\n",
       " 'anterior': 40,\n",
       " 'abdomen': 0,\n",
       " 'excision': 310,\n",
       " 'lateral': 473,\n",
       " 'general': 378,\n",
       " 'patient': 632,\n",
       " 'previously': 679,\n",
       " 'flap': 350,\n",
       " 'loss': 503,\n",
       " 'medial': 526,\n",
       " 'felt': 338,\n",
       " 'medially': 527,\n",
       " 'significant': 809,\n",
       " 'improvement': 424,\n",
       " 'discussed': 254,\n",
       " 'length': 480,\n",
       " 'small': 822,\n",
       " 'ear': 279,\n",
       " 'area': 59,\n",
       " 'great': 387,\n",
       " 'superiorly': 867,\n",
       " 'noted': 595,\n",
       " 'procedure': 685,\n",
       " 'risks': 763,\n",
       " 'benefits': 84,\n",
       " 'complications': 174,\n",
       " 'marked': 518,\n",
       " 'position': 659,\n",
       " 'taken': 884,\n",
       " 'operating': 611,\n",
       " 'room': 764,\n",
       " 'placed': 645,\n",
       " 'supine': 868,\n",
       " 'following': 362,\n",
       " 'adequate': 18,\n",
       " 'anesthesia': 37,\n",
       " 'prepped': 671,\n",
       " 'draped': 272,\n",
       " 'usual': 953,\n",
       " 'sterile': 847,\n",
       " 'fashion': 331,\n",
       " 'injected': 443,\n",
       " 'solution': 826,\n",
       " 'lidocaine': 487,\n",
       " 'epinephrine': 295,\n",
       " 'superior': 866,\n",
       " 'central': 138,\n",
       " 'scar': 778,\n",
       " 'excised': 309,\n",
       " 'dissection': 259,\n",
       " 'continued': 184,\n",
       " 'subcutaneous': 859,\n",
       " 'underlying': 941,\n",
       " 'capsule': 119,\n",
       " 'opened': 610,\n",
       " 'removed': 735,\n",
       " 'table': 883,\n",
       " 'antibiotic': 42,\n",
       " 'bovie': 103,\n",
       " 'cautery': 132,\n",
       " 'released': 730,\n",
       " 'performed': 637,\n",
       " 'release': 729,\n",
       " 'level': 484,\n",
       " 'secured': 788,\n",
       " 'suture': 874,\n",
       " 'greater': 388,\n",
       " 'point': 655,\n",
       " 'good': 383,\n",
       " 'improved': 423,\n",
       " 'completed': 170,\n",
       " 'irrigation': 460,\n",
       " 'drain': 270,\n",
       " 'brought': 110,\n",
       " 'inferior': 435,\n",
       " 'wound': 996,\n",
       " 'incision': 427,\n",
       " 'hemostasis': 408,\n",
       " 'confirmed': 178,\n",
       " 'closed': 161,\n",
       " 'layers': 476,\n",
       " 'running': 769,\n",
       " 'monocryl': 552,\n",
       " 'subcuticular': 860,\n",
       " 'sutures': 876,\n",
       " 'achieved': 9,\n",
       " 'cannula': 117,\n",
       " 'carried': 126,\n",
       " 'approximately': 58,\n",
       " 'ml': 545,\n",
       " 'fat': 332,\n",
       " 'prolene': 688,\n",
       " 'steri': 846,\n",
       " 'strips': 854,\n",
       " 'site': 816,\n",
       " 'dressing': 273,\n",
       " 'surgical': 873,\n",
       " 'extubated': 322,\n",
       " 'recovery': 714,\n",
       " 'condition': 177,\n",
       " 'sponge': 834,\n",
       " 'needle': 577,\n",
       " 'counts': 198,\n",
       " 'correct': 194,\n",
       " 'tolerated': 914,\n",
       " 'estimated': 301,\n",
       " 'multiple': 564,\n",
       " 'vessels': 968,\n",
       " 'vessel': 967,\n",
       " 'cardiac': 121,\n",
       " 'chamber': 141,\n",
       " 'flow': 354,\n",
       " 'reveals': 756,\n",
       " 'return': 753,\n",
       " 'septum': 797,\n",
       " 'aorta': 45,\n",
       " 'arteries': 62,\n",
       " 'sided': 807,\n",
       " 'patent': 630,\n",
       " 'descending': 232,\n",
       " 'motion': 557,\n",
       " 'masses': 521,\n",
       " 'dry': 276,\n",
       " 'eyes': 324,\n",
       " 'kidney': 466,\n",
       " 'mellitus': 531,\n",
       " 'thyroid': 902,\n",
       " 'prior': 681,\n",
       " 'resection': 743,\n",
       " 'mg': 536,\n",
       " 'mcg': 523,\n",
       " 'twice': 935,\n",
       " 'rash': 704,\n",
       " 'long': 501,\n",
       " 'month': 553,\n",
       " 'department': 230,\n",
       " 'married': 519,\n",
       " 'children': 149,\n",
       " 'type': 937,\n",
       " 'mother': 556,\n",
       " 'positive': 661,\n",
       " 'occasional': 605,\n",
       " 'peripheral': 639,\n",
       " 'bladder': 94,\n",
       " 'low': 504,\n",
       " 'obstructive': 602,\n",
       " 'bowel': 104,\n",
       " 'movements': 561,\n",
       " 'examination': 306,\n",
       " 'temperature': 889,\n",
       " 'pulse': 695,\n",
       " 'respiratory': 747,\n",
       " 'rate': 705,\n",
       " 'nourished': 596,\n",
       " 'developed': 234,\n",
       " 'distress': 262,\n",
       " 'eye': 323,\n",
       " 'exam': 305,\n",
       " 'pupils': 697,\n",
       " 'equal': 298,\n",
       " 'round': 766,\n",
       " 'reactive': 708,\n",
       " 'light': 490,\n",
       " 'deep': 219,\n",
       " 'tendon': 892,\n",
       " 'reflexes': 723,\n",
       " 'lower': 505,\n",
       " 'extremities': 320,\n",
       " 'focal': 358,\n",
       " 'midline': 539,\n",
       " 'trachea': 920,\n",
       " 'cervical': 139,\n",
       " 'lymphadenopathy': 511,\n",
       " 'carotid': 124,\n",
       " 'lung': 508,\n",
       " 'sounds': 828,\n",
       " 'regular': 727,\n",
       " 'rhythm': 759,\n",
       " 'murmur': 565,\n",
       " 'abdominal': 1,\n",
       " 'nontender': 590,\n",
       " 'nondistended': 589,\n",
       " 'palpable': 624,\n",
       " 'tenderness': 891,\n",
       " 'upper': 947,\n",
       " 'quadrant': 698,\n",
       " 'appreciated': 55,\n",
       " 'obvious': 604,\n",
       " 'extremity': 321,\n",
       " 'edema': 282,\n",
       " 'pulses': 696,\n",
       " 'mass': 520,\n",
       " 'related': 728,\n",
       " 'gastric': 376,\n",
       " 'bypass': 112,\n",
       " 'appears': 53,\n",
       " 'excellent': 308,\n",
       " 'management': 515,\n",
       " 'vitamin': 977,\n",
       " 'levels': 485,\n",
       " 'proceed': 686,\n",
       " 'work': 992,\n",
       " 'recommended': 713,\n",
       " 'preoperative': 670,\n",
       " 'airway': 27,\n",
       " 'obstruction': 601,\n",
       " 'secondary': 786,\n",
       " 'severe': 798,\n",
       " 'stenosis': 844,\n",
       " 'foreign': 367,\n",
       " 'removal': 733,\n",
       " 'stent': 845,\n",
       " 'material': 522,\n",
       " 'distal': 260,\n",
       " 'placement': 646,\n",
       " 'tube': 930,\n",
       " 'male': 514,\n",
       " 'treated': 926,\n",
       " 'problems': 684,\n",
       " 'additional': 16,\n",
       " 'initial': 441,\n",
       " 'subsequently': 861,\n",
       " 'came': 114,\n",
       " 'hospital': 414,\n",
       " 'evaluation': 303,\n",
       " 'admitted': 22,\n",
       " 'underwent': 942,\n",
       " 'dr': 269,\n",
       " 'extensive': 317,\n",
       " 'changes': 143,\n",
       " 'nature': 571,\n",
       " 'infection': 434,\n",
       " 'speech': 831,\n",
       " 'risk': 762,\n",
       " 'anesthetic': 38,\n",
       " 'intervention': 454,\n",
       " 'stated': 841,\n",
       " 'monitoring': 551,\n",
       " 'sedation': 789,\n",
       " 'elevated': 287,\n",
       " 'inferiorly': 436,\n",
       " 'muscles': 568,\n",
       " 'fascia': 330,\n",
       " 'appeared': 51,\n",
       " 'fusion': 373,\n",
       " 'cartilage': 127,\n",
       " 'easily': 280,\n",
       " 'enlarged': 291,\n",
       " 'divided': 263,\n",
       " 'blunt': 99,\n",
       " 'sharp': 799,\n",
       " 'exposed': 312,\n",
       " 'ring': 761,\n",
       " 'entered': 292,\n",
       " 'incised': 426,\n",
       " 'second': 785,\n",
       " 'sent': 796,\n",
       " 'wall': 979,\n",
       " 'mm': 546,\n",
       " 'visualized': 975,\n",
       " 'able': 2,\n",
       " 'inserted': 446,\n",
       " 'administered': 20,\n",
       " 'revealed': 755,\n",
       " 'showed': 804,\n",
       " 'mid': 537,\n",
       " 'lumen': 507,\n",
       " 'distally': 261,\n",
       " 'place': 644,\n",
       " 'junction': 464,\n",
       " 'endotracheal': 290,\n",
       " 'just': 465,\n",
       " 'needed': 576,\n",
       " 'irrigated': 459,\n",
       " 'interrupted': 453,\n",
       " 'vicryl': 969,\n",
       " 'laterally': 474,\n",
       " 'silk': 811,\n",
       " 'care': 122,\n",
       " 'unit': 943,\n",
       " 'satisfactory': 773,\n",
       " 'status': 843,\n",
       " 'post': 663,\n",
       " 'apparently': 48,\n",
       " 'accident': 8,\n",
       " 'feel': 334,\n",
       " 'states': 842,\n",
       " 'night': 585,\n",
       " 'having': 395,\n",
       " 'morning': 555,\n",
       " 'did': 241,\n",
       " 'make': 513,\n",
       " 'better': 87,\n",
       " 'visit': 972,\n",
       " 'apparent': 47,\n",
       " 'access': 7,\n",
       " 'port': 657,\n",
       " 'standard': 837,\n",
       " 'doing': 265,\n",
       " 'total': 918,\n",
       " 'emergency': 288,\n",
       " 'drug': 275,\n",
       " 'alcohol': 28,\n",
       " 'tobacco': 910,\n",
       " 'chart': 144,\n",
       " 'large': 471,\n",
       " 'antibiotics': 43,\n",
       " 'recently': 712,\n",
       " 'discharged': 252,\n",
       " 'discharge': 251,\n",
       " 'sure': 870,\n",
       " 'problem': 683,\n",
       " 'today': 911,\n",
       " 'laparoscopic': 470,\n",
       " 'presented': 675,\n",
       " 'center': 137,\n",
       " 'treatment': 927,\n",
       " 'associated': 69,\n",
       " 'process': 687,\n",
       " 'routine': 767,\n",
       " 'postoperative': 666,\n",
       " 'utilized': 956,\n",
       " 'control': 188,\n",
       " 'complaints': 168,\n",
       " 'limits': 494,\n",
       " 'hour': 415,\n",
       " 'fever': 341,\n",
       " 'symptoms': 879,\n",
       " 'include': 429,\n",
       " 'office': 606,\n",
       " 'activity': 12,\n",
       " 'reviewed': 758,\n",
       " 'manner': 516,\n",
       " 'grasped': 386,\n",
       " 'local': 500,\n",
       " 'clamp': 154,\n",
       " 'sheath': 800,\n",
       " 'scalpel': 776,\n",
       " 'scissors': 781,\n",
       " 'portion': 658,\n",
       " 'clamped': 155,\n",
       " 'proximal': 692,\n",
       " 'inspected': 448,\n",
       " 'chromic': 151,\n",
       " 'similar': 812,\n",
       " 'applied': 54,\n",
       " 'bilateral': 88,\n",
       " 'gentleman': 379,\n",
       " 'options': 613,\n",
       " 'marcaine': 517,\n",
       " 'proximally': 693,\n",
       " 'cut': 208,\n",
       " 'edges': 283,\n",
       " 'close': 160,\n",
       " 'attention': 73,\n",
       " 'turned': 934,\n",
       " 'end': 289,\n",
       " 'case': 128,\n",
       " 'identified': 419,\n",
       " 'tissues': 909,\n",
       " 'transected': 922,\n",
       " 'tied': 904,\n",
       " 'transferred': 923,\n",
       " 'prostate': 689,\n",
       " 'physical': 642,\n",
       " 'abnormal': 3,\n",
       " 'findings': 347,\n",
       " 'creatinine': 202,\n",
       " 'hemoglobin': 407,\n",
       " 'hematocrit': 405,\n",
       " 'ray': 706,\n",
       " 'course': 199,\n",
       " 'pathology': 631,\n",
       " 'report': 739,\n",
       " 'minimal': 542,\n",
       " 'days': 215,\n",
       " 'benign': 85,\n",
       " 'followed': 361,\n",
       " 'outpatient': 619,\n",
       " 'mr': 562,\n",
       " 'remained': 731,\n",
       " 'operative': 612,\n",
       " 'note': 594,\n",
       " 'wife': 988,\n",
       " 'received': 710,\n",
       " 'specimen': 830,\n",
       " 'hearing': 401,\n",
       " 'regarding': 725,\n",
       " 'plan': 648,\n",
       " 'scheduled': 779,\n",
       " 'change': 142,\n",
       " 'suite': 864,\n",
       " 'oral': 614,\n",
       " 'segment': 791,\n",
       " 'dissected': 258,\n",
       " 'tylenol': 936,\n",
       " 'questions': 699,\n",
       " 'followup': 363,\n",
       " 'gross': 389,\n",
       " 'chills': 150,\n",
       " 'continues': 185,\n",
       " 'taking': 885,\n",
       " 'issues': 461,\n",
       " 'vaginal': 958,\n",
       " 'urine': 949,\n",
       " 'possible': 662,\n",
       " 'rule': 768,\n",
       " 'follow': 360,\n",
       " 'pelvic': 634,\n",
       " 'pelvis': 635,\n",
       " 'recurrent': 718,\n",
       " 'acute': 14,\n",
       " 'renal': 736,\n",
       " 'probably': 682,\n",
       " 'previous': 678,\n",
       " 'passed': 628,\n",
       " 'trial': 928,\n",
       " 'started': 839,\n",
       " 'recent': 711,\n",
       " 'went': 986,\n",
       " 'foley': 359,\n",
       " 'vision': 971,\n",
       " 'lesions': 483,\n",
       " 'systems': 881,\n",
       " 'stage': 836,\n",
       " 'arm': 61,\n",
       " 'unknown': 945,\n",
       " 'colon': 165,\n",
       " 'father': 333,\n",
       " 'sodium': 824,\n",
       " 'coumadin': 196,\n",
       " 'aspirin': 68,\n",
       " 'insulin': 450,\n",
       " 'auscultation': 74,\n",
       " 'bilaterally': 89,\n",
       " 'palpation': 625,\n",
       " 'study': 858,\n",
       " 'thought': 900,\n",
       " 'self': 793,\n",
       " 'lives': 498,\n",
       " 'hours': 416,\n",
       " 'away': 76,\n",
       " 'continue': 183,\n",
       " 'clinic': 157,\n",
       " 'catheter': 129,\n",
       " 'repair': 737,\n",
       " 'informed': 439,\n",
       " 'consent': 179,\n",
       " 'obtained': 603,\n",
       " 'sac': 770,\n",
       " 'electrocautery': 286,\n",
       " 'defect': 220,\n",
       " 'cavity': 133,\n",
       " 'simple': 813,\n",
       " 'saline': 772,\n",
       " 'approximated': 57,\n",
       " 'reported': 740,\n",
       " 'worsening': 995,\n",
       " 'unremarkable': 946,\n",
       " 'provided': 691,\n",
       " 'ultrasound': 939,\n",
       " 'measures': 524,\n",
       " 'evidence': 304,\n",
       " 'appearance': 50,\n",
       " 'tumor': 932,\n",
       " 'spinal': 832,\n",
       " 'base': 80,\n",
       " 'french': 370,\n",
       " 'way': 981,\n",
       " 'balloon': 79,\n",
       " 'episode': 296,\n",
       " 'demonstrated': 227,\n",
       " 'visual': 973,\n",
       " 'resected': 742,\n",
       " 'completion': 172,\n",
       " 'free': 369,\n",
       " 'inflated': 437,\n",
       " 'continuous': 186,\n",
       " 'need': 575,\n",
       " 'mentioned': 534,\n",
       " 'limited': 493,\n",
       " 'positioned': 660,\n",
       " 'lobe': 499,\n",
       " 'posterior': 664,\n",
       " 'initially': 442,\n",
       " 'completely': 171,\n",
       " 'introduced': 457,\n",
       " 'direct': 248,\n",
       " 'fluid': 355,\n",
       " 'episodes': 297,\n",
       " 'dorsal': 266,\n",
       " 'scope': 782,\n",
       " 'entire': 293,\n",
       " 'superficial': 865,\n",
       " 'moderate': 548,\n",
       " 'tip': 907,\n",
       " 'biopsies': 90,\n",
       " 'rest': 749,\n",
       " 'onset': 608,\n",
       " 'unable': 940,\n",
       " 'discomfort': 253,\n",
       " 'parents': 626,\n",
       " 'checked': 146,\n",
       " 'nausea': 572,\n",
       " 'vomiting': 978,\n",
       " 'trauma': 925,\n",
       " 'said': 771,\n",
       " 'resolved': 745,\n",
       " 'sensation': 794,\n",
       " 'medications': 530,\n",
       " 'term': 893,\n",
       " 'delivery': 226,\n",
       " 'review': 757,\n",
       " 'school': 780,\n",
       " 'little': 496,\n",
       " 'murmurs': 566,\n",
       " 'present': 673,\n",
       " 'inguinal': 440,\n",
       " 'slightly': 821,\n",
       " 'range': 703,\n",
       " 'warm': 980,\n",
       " 'grossly': 390,\n",
       " 'increased': 432,\n",
       " 'versus': 965,\n",
       " 'actually': 13,\n",
       " 'fixation': 349,\n",
       " 'alternatives': 33,\n",
       " 'likely': 492,\n",
       " 'later': 472,\n",
       " 'radiation': 702,\n",
       " 'therapy': 897,\n",
       " 'difficult': 244,\n",
       " 'pedicle': 633,\n",
       " 'epidural': 294,\n",
       " 'catheterization': 130,\n",
       " 'diffuse': 246,\n",
       " 'open': 609,\n",
       " 'tract': 921,\n",
       " 'number': 597,\n",
       " 'remove': 734,\n",
       " 'bone': 101,\n",
       " 'iliac': 420,\n",
       " 'spine': 833,\n",
       " 'radial': 701,\n",
       " 'line': 495,\n",
       " 'intravenous': 456,\n",
       " 'rectus': 717,\n",
       " 'described': 233,\n",
       " 'moist': 549,\n",
       " 'exposure': 313,\n",
       " 'quite': 700,\n",
       " 'double': 268,\n",
       " 'posteriorly': 665,\n",
       " 'carefully': 123,\n",
       " 'duct': 277,\n",
       " 'longus': 502,\n",
       " 'plane': 649,\n",
       " 'rectum': 716,\n",
       " 'anteriorly': 41,\n",
       " 'remaining': 732,\n",
       " 'field': 344,\n",
       " 'transverse': 924,\n",
       " 'allowed': 32,\n",
       " 'middle': 538,\n",
       " 'device': 235,\n",
       " 'anastomosis': 35,\n",
       " 'technique': 887,\n",
       " 'layer': 475,\n",
       " 'cc': 134,\n",
       " 'final': 346,\n",
       " 'delivered': 225,\n",
       " 'healthy': 400,\n",
       " 'stitch': 848,\n",
       " 'red': 719,\n",
       " 'cells': 136,\n",
       " 'count': 197,\n",
       " 'told': 913,\n",
       " 'period': 638,\n",
       " 'measuring': 525,\n",
       " 'aspect': 66,\n",
       " 'cord': 192,\n",
       " 'allow': 31,\n",
       " 'consistent': 180,\n",
       " 'betadine': 86,\n",
       " 'areas': 60,\n",
       " 'incisions': 428,\n",
       " 'directed': 249,\n",
       " 'degree': 223,\n",
       " 'withdrawn': 990,\n",
       " 'surface': 871,\n",
       " 'plain': 647,\n",
       " 'blade': 95,\n",
       " 'knife': 468,\n",
       " 'extended': 314,\n",
       " 'created': 201,\n",
       " 'block': 97,\n",
       " 'closure': 162,\n",
       " 'diagnosis': 238,\n",
       " 'grade': 384,\n",
       " 'injury': 445,\n",
       " 'chronic': 152,\n",
       " 'space': 829,\n",
       " 'complex': 173,\n",
       " 'bipolar': 92,\n",
       " 'copiously': 191,\n",
       " 'complete': 169,\n",
       " 'clock': 159,\n",
       " 'th': 896,\n",
       " 'sutured': 875,\n",
       " 'adhesions': 19,\n",
       " 'fevers': 342,\n",
       " 'erythema': 299,\n",
       " 'nose': 593,\n",
       " 'cyanosis': 209,\n",
       " 'cough': 195,\n",
       " 'seizure': 792,\n",
       " 'dose': 267,\n",
       " 'culture': 204,\n",
       " 'results': 751,\n",
       " 'denied': 228,\n",
       " 'baby': 78,\n",
       " 'mom': 550,\n",
       " 'diet': 243,\n",
       " 'normocephalic': 592,\n",
       " 'atraumatic': 71,\n",
       " 'membranes': 532,\n",
       " 'air': 26,\n",
       " 'movement': 560,\n",
       " 'lymph': 510,\n",
       " 'node': 586,\n",
       " 'nerve': 580,\n",
       " 'ligament': 488,\n",
       " 'external': 319,\n",
       " 'common': 167,\n",
       " 'vein': 961,\n",
       " 'nodes': 587,\n",
       " 'section': 787,\n",
       " 'ligated': 489,\n",
       " 'bed': 82,\n",
       " 'cell': 135,\n",
       " 'biopsy': 91,\n",
       " 'perform': 636,\n",
       " 'controlled': 189,\n",
       " 'retracted': 752,\n",
       " 'near': 573,\n",
       " 'forceps': 366,\n",
       " 'region': 726,\n",
       " 'reapproximated': 709,\n",
       " 'involving': 458,\n",
       " 'scan': 777,\n",
       " 'lesion': 482,\n",
       " 'appearing': 52,\n",
       " 'neurologic': 582,\n",
       " 'caucasian': 131,\n",
       " 'decided': 216,\n",
       " 'compression': 176,\n",
       " 'test': 894,\n",
       " 'view': 970,\n",
       " 'suctioned': 863,\n",
       " 'guidewire': 392,\n",
       " 'peritoneum': 640,\n",
       " 'visualization': 974,\n",
       " 'sites': 817,\n",
       " 'bit': 93,\n",
       " 'pleasant': 652,\n",
       " 'clubbing': 163,\n",
       " 'residual': 744,\n",
       " 'asked': 65,\n",
       " 'contact': 182,\n",
       " 'extending': 315,\n",
       " 'overall': 620,\n",
       " 'physician': 643,\n",
       " 'health': 399,\n",
       " 'active': 10,\n",
       " 'age': 24,\n",
       " 'abnormalities': 4,\n",
       " 'carcinoma': 120,\n",
       " 'half': 393,\n",
       " 'state': 840,\n",
       " 'medical': 528,\n",
       " 'degrees': 224,\n",
       " 'tear': 886,\n",
       " 'sign': 808,\n",
       " 'non': 588,\n",
       " 'referred': 721,\n",
       " 'component': 175,\n",
       " 'minute': 543,\n",
       " 'avoid': 75,\n",
       " 'wire': 989,\n",
       " 'dilated': 247,\n",
       " 'result': 750,\n",
       " 'oblique': 600,\n",
       " 'flushed': 357,\n",
       " 'straight': 851,\n",
       " 'staples': 838,\n",
       " 'nylon': 599,\n",
       " 'tubes': 931,\n",
       " 'mouth': 559,\n",
       " 'diarrhea': 240,\n",
       " 'respirations': 746,\n",
       " 'symmetric': 878,\n",
       " 'partial': 627,\n",
       " 'primary': 680,\n",
       " 'feeling': 335,\n",
       " 'extension': 316,\n",
       " 'saw': 775,\n",
       " 'smoking': 823,\n",
       " 'saturation': 774,\n",
       " 'glucose': 381,\n",
       " 'potassium': 667,\n",
       " 'calcium': 113,\n",
       " 'explained': 311,\n",
       " 'needs': 578,\n",
       " 'minutes': 544,\n",
       " 'examined': 307,\n",
       " 'somewhat': 827,\n",
       " 'shows': 805,\n",
       " 'consultation': 181,\n",
       " 'child': 148,\n",
       " 'canal': 115,\n",
       " 'internal': 452,\n",
       " 'finger': 348,\n",
       " 'reduction': 720,\n",
       " 'structures': 856,\n",
       " 'shoulder': 803,\n",
       " 'check': 145,\n",
       " 'lens': 481,\n",
       " 'evaluated': 302,\n",
       " 'flexion': 351,\n",
       " 'returned': 754,\n",
       " 'weakness': 982,\n",
       " 'based': 81,\n",
       " 'abscess': 5,\n",
       " 'help': 404,\n",
       " 'vascular': 960,\n",
       " 'tunnel': 933,\n",
       " 'addition': 15,\n",
       " 'trocar': 929,\n",
       " 'uterus': 955,\n",
       " 'utilizing': 957,\n",
       " 'cystic': 211,\n",
       " 'sinus': 815,\n",
       " 'rays': 707,\n",
       " 'increasing': 433,\n",
       " 'cultures': 205,\n",
       " 'disorder': 257,\n",
       " 'shunt': 806,\n",
       " 'information': 438,\n",
       " 'decreased': 218,\n",
       " 'cuff': 203,\n",
       " 'plate': 651,\n",
       " 'tourniquet': 919,\n",
       " 'inch': 425,\n",
       " 'pneumonia': 654,\n",
       " 'daughter': 213,\n",
       " 'workup': 993,\n",
       " 'hematoma': 406,\n",
       " 'diagnosed': 237,\n",
       " 'headache': 397,\n",
       " 'numbness': 598,\n",
       " 'anxiety': 44,\n",
       " 'depression': 231,\n",
       " 'injection': 444,\n",
       " 'oropharynx': 617,\n",
       " 'neurological': 583,\n",
       " 'strength': 852,\n",
       " 'headaches': 398,\n",
       " 'feet': 337,\n",
       " 'instructed': 449,\n",
       " 'order': 615,\n",
       " 'images': 421,\n",
       " 'fluoroscopy': 356,\n",
       " 'motor': 558,\n",
       " 'abuse': 6,\n",
       " 'breathing': 109,\n",
       " 'femoral': 340,\n",
       " 'cyst': 210,\n",
       " 'tone': 915,\n",
       " 'current': 206,\n",
       " 'admission': 21,\n",
       " 'gait': 374,\n",
       " 'repeat': 738,\n",
       " 'increase': 431,\n",
       " 'reports': 741,\n",
       " 'advanced': 23,\n",
       " 'contrast': 187,\n",
       " 'activities': 11,\n",
       " 'clinical': 158,\n",
       " 'guide': 391,\n",
       " 'gauge': 377,\n",
       " 'cervix': 140,\n",
       " 'aspiration': 67,\n",
       " 'graft': 385,\n",
       " 'woman': 991,\n",
       " 'metatarsal': 535,\n",
       " 'screw': 783,\n",
       " 'degenerative': 222,\n",
       " 'copious': 190,\n",
       " 'reflected': 722,\n",
       " 'extensor': 318,\n",
       " 'capsular': 118,\n",
       " 'phalanx': 641,\n",
       " 'flexor': 352,\n",
       " 'drill': 274,\n",
       " 'insertion': 447,\n",
       " 'osteotomy': 618,\n",
       " 'plantar': 650,\n",
       " 'screws': 784,\n",
       " 'amounts': 34,\n",
       " 'died': 242,\n",
       " 'thigh': 898,\n",
       " 'main': 512,\n",
       " 'wrist': 997,\n",
       " 'frontal': 371,\n",
       " 'lid': 486,\n",
       " 'lead': 477,\n",
       " 'branch': 106,\n",
       " 'studies': 857,\n",
       " 'dura': 278,\n",
       " 'brain': 105,\n",
       " 'uterine': 954,\n",
       " 'tooth': 917,\n",
       " 'esophagus': 300,\n",
       " 'stomach': 849,\n",
       " 'circumflex': 153,\n",
       " 'suction': 862,\n",
       " 'units': 944,\n",
       " 'ulnar': 938,\n",
       " 'tongue': 916,\n",
       " 'root': 765,\n",
       " 'syndrome': 880,\n",
       " 'decompression': 217,\n",
       " 'intraoperative': 455,\n",
       " 'temporal': 890,\n",
       " 'facial': 326,\n",
       " 'pregnancy': 669,\n",
       " 'fall': 328,\n",
       " 'disc': 250,\n",
       " 'lumbar': 506,\n",
       " 'foramen': 365,\n",
       " 'vertebral': 966,\n",
       " 'bony': 102,\n",
       " 'immediately': 422,\n",
       " 'protein': 690,\n",
       " 'toe': 912,\n",
       " 'tibial': 903,\n",
       " 'face': 325,\n",
       " 'oxygen': 621,\n",
       " 'hip': 411,\n",
       " 'pleural': 653,\n",
       " 'anemia': 36,\n",
       " 'teeth': 888,\n",
       " 'myocardial': 569,\n",
       " 'disk': 256,\n",
       " 'height': 403,\n",
       " 'fifth': 345,\n",
       " 'axillary': 77,\n",
       " 'testing': 895,\n",
       " 'response': 748,\n",
       " 'echocardiogram': 281,\n",
       " 'carpal': 125,\n",
       " 'presentation': 674,\n",
       " 'fracture': 368,\n",
       " 'joints': 463,\n",
       " 'sensory': 795,\n",
       " 'husband': 417,\n",
       " 'memory': 533,\n",
       " 'colonoscopy': 166,\n",
       " 'bruits': 111}"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-panel",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "literary-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "loose-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Random Forest\", \n",
    "         \"Neural Net\", \"AdaBoost\"]\n",
    "\n",
    "names2 = [\"Gaussian Process\", \"Decision Tree\", \"Naive Bayes\", \"Logistic Regression\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier()]\n",
    "\n",
    "classifiers2 = [GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "               #DecisionTreeClassifier(max_depth=5),\n",
    "               GaussianNB(),\n",
    "               LogisticRegression()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "known-broad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KNeighborsClassifier(n_neighbors=3),\n",
       " SVC(C=0.025, kernel='linear'),\n",
       " SVC(C=1, gamma=2),\n",
       " RandomForestClassifier(max_depth=5, max_features=1, n_estimators=10),\n",
       " MLPClassifier(alpha=1, max_iter=1000),\n",
       " AdaBoostClassifier()]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "cleared-validity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors F1 Score Micro: 20.18%\n",
      "Nearest Neighbors F1 Score Macro: 4.18%\n",
      "Nearest Neighbors F1 Score Weighted: 31.07%\n",
      "Linear SVM F1 Score Micro: 70.18%\n",
      "Linear SVM F1 Score Macro: 8.58%\n",
      "Linear SVM F1 Score Weighted: 60.20%\n",
      "RBF SVM F1 Score Micro: 25.44%\n",
      "RBF SVM F1 Score Macro: 4.33%\n",
      "RBF SVM F1 Score Weighted: 33.13%\n",
      "Random Forest F1 Score Micro: 69.74%\n",
      "Random Forest F1 Score Macro: 8.35%\n",
      "Random Forest F1 Score Weighted: 58.57%\n",
      "Neural Net F1 Score Micro: 52.63%\n",
      "Neural Net F1 Score Macro: 11.82%\n",
      "Neural Net F1 Score Weighted: 54.67%\n",
      "AdaBoost F1 Score Micro: 48.68%\n",
      "AdaBoost F1 Score Macro: 6.38%\n",
      "AdaBoost F1 Score Weighted: 53.72%\n"
     ]
    }
   ],
   "source": [
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(train_X_processed, train_y)\n",
    "    y_pred = clf.predict(val_X_processed)\n",
    "    \n",
    "    # evaluate predictions\n",
    "    f1_micro = f1_score(val_y, y_pred, average=\"micro\")\n",
    "    f1_macro = f1_score(val_y, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(val_y, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(\"%s F1 Score Micro: %.2f%%\" % (name,f1_micro * 100.0))\n",
    "    print(\"%s F1 Score Macro: %.2f%%\" % (name,f1_macro * 100.0))\n",
    "    print(\"%s F1 Score Weighted: %.2f%%\" % (name,f1_weighted * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "large-absence",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-a87e04eb218a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifiers2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X_processed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X_processed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# evaluate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/gaussian_process/_gpc.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    662\u001b[0m                                  % self.multi_class)\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;31m# n_jobs > 1 in can results in slower performance due to the overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;31m# of spawning threads.  See joblib issue #112.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(delayed(_fit_binary)(\n\u001b[0m\u001b[1;32m    282\u001b[0m             self.estimator, X, column, classes=[\n\u001b[1;32m    283\u001b[0m                 \u001b[0;34m\"not %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[0;34m(estimator, X, y, classes)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/gaussian_process/_gpc.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;31m# First optimize starting from theta specified in kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             optima = [self._constrained_optimization(obj_func,\n\u001b[0m\u001b[1;32m    213\u001b[0m                                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                                                      self.kernel_.bounds)]\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/gaussian_process/_gpc.py\u001b[0m in \u001b[0;36m_constrained_optimization\u001b[0;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_constrained_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fmin_l_bfgs_b\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             opt_res = scipy.optimize.minimize(\n\u001b[0m\u001b[1;32m    446\u001b[0m                 \u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                 bounds=bounds)\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    617\u001b[0m                                   **options)\n\u001b[1;32m    618\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    620\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    621\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0miprint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n\u001b[0m\u001b[1;32m    307\u001b[0m                                   \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_bounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                                   finite_diff_rel_step=finite_diff_rel_step)\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;31m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0m\u001b[1;32m    262\u001b[0m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# Gradient evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/gaussian_process/_gpc.py\u001b[0m in \u001b[0;36mobj_func\u001b[0;34m(theta, eval_gradient)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                     lml, grad = self.log_marginal_likelihood(\n\u001b[0m\u001b[1;32m    205\u001b[0m                         theta, eval_gradient=True, clone_kernel=False)\n\u001b[1;32m    206\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/gaussian_process/_gpc.py\u001b[0m in \u001b[0;36mlog_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0md_Z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;31m# XXX: Get rid of the np.diag() in the next line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW_sr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcho_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_sr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Line 7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_sr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Line 8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;31m# Line 9: (use einsum to compute np.diag(C.T.dot(C))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36mcho_solve\u001b[0;34m(c_and_lower, b, overwrite_b, check_finite)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0mpotrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lapack_funcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'potrs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpotrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverwrite_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         raise ValueError('illegal value in %dth argument of internal potrs'\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for name, clf in zip(names2, classifiers2):\n",
    "    clf.fit(train_X_processed.toarray(), train_y)\n",
    "    y_pred = clf.predict(val_X_processed)\n",
    "    \n",
    "    # evaluate predictions\n",
    "    f1_micro = f1_score(val_y, y_pred, average=\"micro\")\n",
    "    f1_macro = f1_score(val_y, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(val_y, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(\"%s F1 Score Micro: %.2f%%\" % (name,f1_micro * 100.0))\n",
    "    print(\"%s F1 Score Macro: %.2f%%\" % (name,f1_macro * 100.0))\n",
    "    print(\"%s F1 Score Weighted: %.2f%%\" % (name,f1_weighted * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-indicator",
   "metadata": {},
   "source": [
    "#### Improving Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "wired-mongolia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier F1 Score Micro: 69.74%\n",
      "Random Forest Classifier F1 Score Macro: 8.26%\n",
      "Random Forest Classifier F1 Score Weighted: 57.96%\n"
     ]
    }
   ],
   "source": [
    "name = \"Random Forest Classifier\"\n",
    "rfc = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "rfc.fit(train_X_processed, train_y)\n",
    "y_pred = rfc.predict(val_X_processed)\n",
    "\n",
    "f1_micro = f1_score(val_y, y_pred, average=\"micro\")\n",
    "f1_macro = f1_score(val_y, y_pred, average=\"macro\")\n",
    "f1_weighted = f1_score(val_y, y_pred, average=\"weighted\")\n",
    "    \n",
    "print(\"%s F1 Score Micro: %.2f%%\" % (name,f1_micro * 100.0))\n",
    "print(\"%s F1 Score Macro: %.2f%%\" % (name,f1_macro * 100.0))\n",
    "print(\"%s F1 Score Weighted: %.2f%%\" % (name,f1_weighted * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "coordinated-canon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier F1 Score Micro: 70.18%\n",
      "Random Forest Classifier F1 Score Macro: 8.38%\n",
      "Random Forest Classifier F1 Score Weighted: 58.79%\n",
      "Random Forest Classifier F1 Score Micro: 70.18%\n",
      "Random Forest Classifier F1 Score Macro: 8.38%\n",
      "Random Forest Classifier F1 Score Weighted: 58.79%\n",
      "Random Forest Classifier F1 Score Micro: 70.18%\n",
      "Random Forest Classifier F1 Score Macro: 8.36%\n",
      "Random Forest Classifier F1 Score Weighted: 58.63%\n",
      "Random Forest Classifier F1 Score Micro: 70.18%\n",
      "Random Forest Classifier F1 Score Macro: 8.47%\n",
      "Random Forest Classifier F1 Score Weighted: 59.41%\n"
     ]
    }
   ],
   "source": [
    "name = \"Random Forest Classifier\"\n",
    "\n",
    "n_estimators = [10, 100, 200, 500]\n",
    "\n",
    "for i in n_estimators:\n",
    "    rfc_classifier = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "    rfc_classifier.fit(train_X_processed, train_y)\n",
    "    y_pred = rfc_classifier.predict(val_X_processed)\n",
    "    \n",
    "    f1_micro = f1_score(val_y, y_pred, average=\"micro\")\n",
    "    f1_macro = f1_score(val_y, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(val_y, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(\"Random Forest Classifier number of trees %s F1 Score Micro: %.2f%%\" % (i,f1_micro * 100.0))\n",
    "    print(\"Random Forest Classifier number of trees %s F1 Score Macro: %.2f%%\" % (i,f1_macro * 100.0))\n",
    "    print(\"Random Forest Classifier number of trees %s F1 Score Weighted: %.2f%%\" % (i,f1_weighted * 100.0))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "labeled-software",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier F1 Score Micro: 70.18%\n",
      "Random Forest Classifier F1 Score Macro: 8.27%\n",
      "Random Forest Classifier F1 Score Weighted: 58.03%\n",
      "Random Forest Classifier F1 Score Micro: 70.18%\n",
      "Random Forest Classifier F1 Score Macro: 8.63%\n",
      "Random Forest Classifier F1 Score Weighted: 60.53%\n",
      "Random Forest Classifier F1 Score Micro: 70.18%\n",
      "Random Forest Classifier F1 Score Macro: 8.77%\n",
      "Random Forest Classifier F1 Score Weighted: 61.52%\n",
      "Random Forest Classifier F1 Score Micro: 69.74%\n",
      "Random Forest Classifier F1 Score Macro: 8.91%\n",
      "Random Forest Classifier F1 Score Weighted: 62.51%\n",
      "Random Forest Classifier F1 Score Micro: 68.42%\n",
      "Random Forest Classifier F1 Score Macro: 17.33%\n",
      "Random Forest Classifier F1 Score Weighted: 64.05%\n",
      "Random Forest Classifier F1 Score Micro: 68.86%\n",
      "Random Forest Classifier F1 Score Macro: 17.36%\n",
      "Random Forest Classifier F1 Score Weighted: 64.27%\n",
      "Random Forest Classifier F1 Score Micro: 67.98%\n",
      "Random Forest Classifier F1 Score Macro: 8.22%\n",
      "Random Forest Classifier F1 Score Weighted: 63.42%\n",
      "Random Forest Classifier F1 Score Micro: 70.18%\n",
      "Random Forest Classifier F1 Score Macro: 8.74%\n",
      "Random Forest Classifier F1 Score Weighted: 61.36%\n"
     ]
    }
   ],
   "source": [
    "max_features = [1, 5, 10, 20, 30, 'auto', 'sqrt', 'log2']\n",
    "name = \"Random Forest Classifier\"\n",
    "\n",
    "for i in max_features:\n",
    "    rfc = RandomForestClassifier(max_depth=5, n_estimators=500, max_features=i)\n",
    "    rfc.fit(train_X_processed, train_y)\n",
    "    y_pred = rfc.predict(val_X_processed)\n",
    "    \n",
    "    f1_micro = f1_score(val_y, y_pred, average=\"micro\")\n",
    "    f1_macro = f1_score(val_y, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(val_y, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(\"Random Forest Classifier max_feature %s F1 Score Micro: %.2f%%\" % (i,f1_micro * 100.0))\n",
    "    print(\"Random Forest Classifier max_feature %s F1 Score Macro: %.2f%%\" % (i,f1_macro * 100.0))\n",
    "    print(\"Random Forest Classifier max_feature %s F1 Score Weighted: %.2f%%\" % (i,f1_weighted * 100.0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "breathing-computer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier F1 Score Micro: 70.18%\n",
      "Random Forest Classifier F1 Score Macro: 8.72%\n",
      "Random Forest Classifier F1 Score Weighted: 61.19%\n",
      "Random Forest Classifier F1 Score Micro: 70.18%\n",
      "Random Forest Classifier F1 Score Macro: 8.74%\n",
      "Random Forest Classifier F1 Score Weighted: 61.36%\n"
     ]
    }
   ],
   "source": [
    "criterions = ['entropy', 'gini']\n",
    "name = \"Random Forest Classifier\"\n",
    "\n",
    "for i in criterions:\n",
    "    rfc = RandomForestClassifier(max_depth=5, n_estimators=500, max_features=10, criterion=i)\n",
    "    rfc.fit(train_X_processed, train_y)\n",
    "    y_pred = rfc.predict(val_X_processed)\n",
    "    \n",
    "    f1_micro = f1_score(val_y, y_pred, average=\"micro\")\n",
    "    f1_macro = f1_score(val_y, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(val_y, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(\"Random Forest Classifier criterion %s F1 Score Micro: %.2f%%\" % (i,f1_micro * 100.0))\n",
    "    print(\"Random Forest Classifier criterion %s F1 Score Macro: %.2f%%\" % (i,f1_macro * 100.0))\n",
    "    print(\"Random Forest Classifier criterion %s F1 Score Weighted: %.2f%%\" % (i,f1_weighted * 100.0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "played-wallace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier F1 Score Micro: 70.18%\n",
      "Random Forest Classifier F1 Score Macro: 9.16%\n",
      "Random Forest Classifier F1 Score Weighted: 57.88%\n",
      "Random Forest Classifier F1 Score Micro: 70.18%\n",
      "Random Forest Classifier F1 Score Macro: 8.74%\n",
      "Random Forest Classifier F1 Score Weighted: 61.36%\n",
      "Random Forest Classifier F1 Score Micro: 63.60%\n",
      "Random Forest Classifier F1 Score Macro: 13.34%\n",
      "Random Forest Classifier F1 Score Weighted: 61.31%\n",
      "Random Forest Classifier F1 Score Micro: 27.63%\n",
      "Random Forest Classifier F1 Score Macro: 3.72%\n",
      "Random Forest Classifier F1 Score Weighted: 35.62%\n",
      "Random Forest Classifier F1 Score Micro: 24.12%\n",
      "Random Forest Classifier F1 Score Macro: 2.92%\n",
      "Random Forest Classifier F1 Score Weighted: 32.12%\n"
     ]
    }
   ],
   "source": [
    "max_depths = [1, 5, 10, 20, 50]\n",
    "name = \"Random Forest Classifier\"\n",
    "\n",
    "for i in max_depths:\n",
    "    rfc = RandomForestClassifier(max_depth=i, n_estimators=500, max_features=10, criterion='gini')\n",
    "    rfc.fit(train_X_processed, train_y)\n",
    "    y_pred = rfc.predict(val_X_processed)\n",
    "    \n",
    "    f1_micro = f1_score(val_y, y_pred, average=\"micro\")\n",
    "    f1_macro = f1_score(val_y, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(val_y, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(\"Random Forest Classifier max_depth %s F1 Score Micro: %.2f%%\" % (i,f1_micro * 100.0))\n",
    "    print(\"Random Forest Classifier max_depth %s F1 Score Macro: %.2f%%\" % (i,f1_macro * 100.0))\n",
    "    print(\"Random Forest Classifier max_depth %s F1 Score Weighted: %.2f%%\" % (i,f1_weighted * 100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "eligible-thing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier F1 Score Micro: 70.18%\n",
      "Random Forest Classifier F1 Score Macro: 8.70%\n",
      "Random Forest Classifier F1 Score Weighted: 61.02%\n",
      "Random Forest Classifier F1 Score Micro: 70.18%\n",
      "Random Forest Classifier F1 Score Macro: 8.74%\n",
      "Random Forest Classifier F1 Score Weighted: 61.36%\n"
     ]
    }
   ],
   "source": [
    "bootstrap_options = ['True', 'False']\n",
    "name = \"Random Forest Classifier\"\n",
    "\n",
    "for i in bootstrap_options:\n",
    "    rfc = RandomForestClassifier(max_depth=5, n_estimators=500, max_features=10, criterion='gini', bootstrap=i)\n",
    "    rfc.fit(train_X_processed, train_y)\n",
    "    y_pred = rfc.predict(val_X_processed)\n",
    "    \n",
    "    f1_micro = f1_score(val_y, y_pred, average=\"micro\")\n",
    "    f1_macro = f1_score(val_y, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(val_y, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(\"Random Forest Classifier bootstrap %s F1 Score Micro: %.2f%%\" % (i,f1_micro * 100.0))\n",
    "    print(\"Random Forest Classifier bootstrap %s F1 Score Macro: %.2f%%\" % (i,f1_macro * 100.0))\n",
    "    print(\"Random Forest Classifier bootstrap %s F1 Score Weighted: %.2f%%\" % (i,f1_weighted * 100.0)) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "metropolitan-coordinate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier F1 Score Micro: 9.65%\n",
      "Random Forest Classifier F1 Score Macro: 10.95%\n",
      "Random Forest Classifier F1 Score Weighted: 12.39%\n",
      "Random Forest Classifier F1 Score Micro: 9.65%\n",
      "Random Forest Classifier F1 Score Macro: 9.39%\n",
      "Random Forest Classifier F1 Score Weighted: 12.88%\n",
      "Random Forest Classifier F1 Score Micro: 70.18%\n",
      "Random Forest Classifier F1 Score Macro: 8.82%\n",
      "Random Forest Classifier F1 Score Weighted: 61.86%\n"
     ]
    }
   ],
   "source": [
    "class_weights = ['balanced', 'balanced_subsample', None]\n",
    "\n",
    "name = \"Random Forest Classifier\"\n",
    "\n",
    "for i in class_weights:\n",
    "    rfc = RandomForestClassifier(max_depth=5, \n",
    "                                 n_estimators=500, \n",
    "                                 max_features=10, \n",
    "                                 criterion='gini', \n",
    "                                 bootstrap=False, \n",
    "                                 class_weight=i)\n",
    "    rfc.fit(train_X_processed, train_y)\n",
    "    y_pred = rfc.predict(val_X_processed)\n",
    "    \n",
    "    f1_micro = f1_score(val_y, y_pred, average=\"micro\")\n",
    "    f1_macro = f1_score(val_y, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(val_y, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(\"Random Forest Classifier class_weight %s F1 Score Micro: %.2f%%\" % (i,f1_micro * 100.0))\n",
    "    print(\"Random Forest Classifier class_weight %s F1 Score Macro: %.2f%%\" % (i,f1_macro * 100.0))\n",
    "    print(\"Random Forest Classifier class_weight %s F1 Score Weighted: %.2f%%\" % (i,f1_weighted * 100.0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-validation",
   "metadata": {},
   "source": [
    "#### XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "certain-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_y.tolist())\n",
    "xgb_train_y = le.transform(train_y.tolist())\n",
    "\n",
    "xgb_val_y = le.transform(val_y.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "thirty-tampa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:16] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB Classifier F1 Score Micro: 40.35%\n",
      "XGB Classifier F1 Score Macro: 6.24%\n",
      "XGB Classifier F1 Score Weighted: 49.33%\n"
     ]
    }
   ],
   "source": [
    "name = \"XGB Classifier\"\n",
    "xgbclassifier = xgb.XGBClassifier(learning_rate=0.01, \n",
    "                                  reg_lambda=3,\n",
    "                                  objective='multi:softmax')\n",
    "\n",
    "xgbclassifier.fit(train_X_processed, xgb_train_y)\n",
    "\n",
    "y_pred = xgbclassifier.predict(val_X_processed)\n",
    "f1_micro = f1_score(xgb_val_y, y_pred, average=\"micro\")\n",
    "f1_macro = f1_score(xgb_val_y, y_pred, average=\"macro\")\n",
    "f1_weighted = f1_score(xgb_val_y, y_pred, average=\"weighted\")\n",
    "    \n",
    "print(\"%s F1 Score Micro: %.2f%%\" % (name,f1_micro * 100.0))\n",
    "print(\"%s F1 Score Macro: %.2f%%\" % (name,f1_macro * 100.0))\n",
    "print(\"%s F1 Score Weighted: %.2f%%\" % (name,f1_weighted * 100.0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "divided-appreciation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:20:25] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB Classifier F1 Score Micro: 40.35%\n",
      "XGB Classifier F1 Score Macro: 6.24%\n",
      "XGB Classifier F1 Score Weighted: 49.33%\n",
      "[22:21:29] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier F1 Score Micro: 70.18%\n",
      "XGB Classifier F1 Score Macro: 9.16%\n",
      "XGB Classifier F1 Score Weighted: 57.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:21:33] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB Classifier F1 Score Micro: 39.91%\n",
      "XGB Classifier F1 Score Macro: 6.22%\n",
      "XGB Classifier F1 Score Weighted: 48.97%\n"
     ]
    }
   ],
   "source": [
    "name = \"XGB Classifier\"\n",
    "\n",
    "boosters = ['gbtree', 'gblinear', 'dart']\n",
    "\n",
    "for i in boosters:\n",
    "    xgbclassifier = xgb.XGBClassifier(learning_rate=0.01,\n",
    "                                      booster = i,\n",
    "                                      reg_lambda=3,\n",
    "                                      objective='multi:softmax')\n",
    "    \n",
    "    xgbclassifier.fit(train_X_processed, xgb_train_y)\n",
    "    y_pred = xgbclassifier.predict(val_X_processed)\n",
    "    f1_micro = f1_score(xgb_val_y, y_pred, average=\"micro\")\n",
    "    f1_macro = f1_score(xgb_val_y, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(xgb_val_y, y_pred, average=\"weighted\")\n",
    "\n",
    "    print(\"%s F1 Score Micro: %.2f%%\" % (name,f1_micro * 100.0))\n",
    "    print(\"%s F1 Score Macro: %.2f%%\" % (name,f1_macro * 100.0))\n",
    "    print(\"%s F1 Score Weighted: %.2f%%\" % (name,f1_weighted * 100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "horizontal-variance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:23:57] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB Classifier F1 Score Micro: 70.18%\n",
      "XGB Classifier F1 Score Macro: 9.16%\n",
      "XGB Classifier F1 Score Weighted: 57.88%\n",
      "[22:24:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier F1 Score Micro: 70.18%\n",
      "XGB Classifier F1 Score Macro: 9.16%\n",
      "XGB Classifier F1 Score Weighted: 57.88%\n",
      "[22:24:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier F1 Score Micro: 70.18%\n",
      "XGB Classifier F1 Score Macro: 9.16%\n",
      "XGB Classifier F1 Score Weighted: 57.88%\n",
      "[22:24:05] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier F1 Score Micro: 70.18%\n",
      "XGB Classifier F1 Score Macro: 9.16%\n",
      "XGB Classifier F1 Score Weighted: 57.88%\n",
      "[22:24:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier F1 Score Micro: 0.00%\n",
      "XGB Classifier F1 Score Macro: 0.00%\n",
      "XGB Classifier F1 Score Weighted: 0.00%\n",
      "[22:24:09] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier F1 Score Micro: 70.18%\n",
      "XGB Classifier F1 Score Macro: 9.16%\n",
      "XGB Classifier F1 Score Weighted: 57.88%\n"
     ]
    }
   ],
   "source": [
    "name = \"XGB Classifier\"\n",
    "\n",
    "learning_rates = [0.001, 0.01, 0.1, 1, 5, 10]\n",
    "\n",
    "for i in learning_rates:\n",
    "    xgbclassifier = xgb.XGBClassifier(learning_rate=i,\n",
    "                                      booster = 'gblinear',\n",
    "                                      reg_lambda=3,\n",
    "                                      objective='multi:softmax')\n",
    "    \n",
    "    xgbclassifier.fit(train_X_processed, xgb_train_y)\n",
    "    y_pred = xgbclassifier.predict(val_X_processed)\n",
    "    f1_micro = f1_score(xgb_val_y, y_pred, average=\"micro\")\n",
    "    f1_macro = f1_score(xgb_val_y, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(xgb_val_y, y_pred, average=\"weighted\")\n",
    "\n",
    "    print(\"%s F1 Score Micro: %.2f%%\" % (name,f1_micro * 100.0))\n",
    "    print(\"%s F1 Score Macro: %.2f%%\" % (name,f1_macro * 100.0))\n",
    "    print(\"%s F1 Score Weighted: %.2f%%\" % (name,f1_weighted * 100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "accessory-quilt",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:24:23] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB Classifier F1 Score Micro: 62.72%\n",
      "XGB Classifier F1 Score Macro: 12.00%\n",
      "XGB Classifier F1 Score Weighted: 60.69%\n",
      "[22:24:26] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier F1 Score Micro: 70.18%\n",
      "XGB Classifier F1 Score Macro: 8.47%\n",
      "XGB Classifier F1 Score Weighted: 59.41%\n",
      "[22:24:28] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier F1 Score Micro: 70.18%\n",
      "XGB Classifier F1 Score Macro: 9.16%\n",
      "XGB Classifier F1 Score Weighted: 57.88%\n",
      "[22:24:31] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier F1 Score Micro: 70.18%\n",
      "XGB Classifier F1 Score Macro: 9.16%\n",
      "XGB Classifier F1 Score Weighted: 57.88%\n",
      "[22:24:34] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier F1 Score Micro: 70.18%\n",
      "XGB Classifier F1 Score Macro: 9.16%\n",
      "XGB Classifier F1 Score Weighted: 57.88%\n",
      "[22:24:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier F1 Score Micro: 70.18%\n",
      "XGB Classifier F1 Score Macro: 9.16%\n",
      "XGB Classifier F1 Score Weighted: 57.88%\n"
     ]
    }
   ],
   "source": [
    "name = \"XGB Classifier\"\n",
    "\n",
    "reg_lambdas = [0.001, 0.01, 0.1, 1, 5, 10]\n",
    "\n",
    "for i in reg_lambdas:\n",
    "    xgbclassifier = xgb.XGBClassifier(learning_rate=0.01,\n",
    "                                      booster = 'gblinear',\n",
    "                                      reg_lambda=i,\n",
    "                                      objective='multi:softmax')\n",
    "    \n",
    "    xgbclassifier.fit(train_X_processed, xgb_train_y)\n",
    "    y_pred = xgbclassifier.predict(val_X_processed)\n",
    "    f1_micro = f1_score(xgb_val_y, y_pred, average=\"micro\")\n",
    "    f1_macro = f1_score(xgb_val_y, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(xgb_val_y, y_pred, average=\"weighted\")\n",
    "\n",
    "    print(\"%s F1 Score Micro: %.2f%%\" % (name,f1_micro * 100.0))\n",
    "    print(\"%s F1 Score Macro: %.2f%%\" % (name,f1_macro * 100.0))\n",
    "    print(\"%s F1 Score Weighted: %.2f%%\" % (name,f1_weighted * 100.0)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "unusual-scholar",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:39:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB Classifier F1 Score Micro: 70.18%\n",
      "XGB Classifier F1 Score Macro: 9.16%\n",
      "XGB Classifier F1 Score Weighted: 57.88%\n",
      "[15:39:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier F1 Score Micro: 70.18%\n",
      "XGB Classifier F1 Score Macro: 9.16%\n",
      "XGB Classifier F1 Score Weighted: 57.88%\n",
      "[15:39:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier F1 Score Micro: 70.18%\n",
      "XGB Classifier F1 Score Macro: 9.16%\n",
      "XGB Classifier F1 Score Weighted: 57.88%\n",
      "[15:39:04] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier F1 Score Micro: 70.18%\n",
      "XGB Classifier F1 Score Macro: 9.16%\n",
      "XGB Classifier F1 Score Weighted: 57.88%\n",
      "[15:39:05] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier F1 Score Micro: 70.18%\n",
      "XGB Classifier F1 Score Macro: 9.16%\n",
      "XGB Classifier F1 Score Weighted: 57.88%\n",
      "[15:39:07] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier F1 Score Micro: 70.18%\n",
      "XGB Classifier F1 Score Macro: 9.16%\n",
      "XGB Classifier F1 Score Weighted: 57.88%\n"
     ]
    }
   ],
   "source": [
    "name = \"XGB Classifier\"\n",
    "\n",
    "reg_alphas = [0.001, 0.01, 0.1, 1, 5, 10]\n",
    "\n",
    "for i in reg_alphas:\n",
    "    xgbclassifier = xgb.XGBClassifier(learning_rate=0.01,\n",
    "                                      booster = 'gblinear',\n",
    "                                      reg_lambda=0.01,\n",
    "                                      reg_alpha=i,\n",
    "                                      objective='multi:softmax')\n",
    "    \n",
    "    xgbclassifier.fit(train_X_processed, xgb_train_y)\n",
    "    y_pred = xgbclassifier.predict(val_X_processed)\n",
    "    f1_micro = f1_score(xgb_val_y, y_pred, average=\"micro\")\n",
    "    f1_macro = f1_score(xgb_val_y, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(xgb_val_y, y_pred, average=\"weighted\")\n",
    "\n",
    "    print(\"%s F1 Score Micro: %.2f%%\" % (name,f1_micro * 100.0))\n",
    "    print(\"%s F1 Score Macro: %.2f%%\" % (name,f1_macro * 100.0))\n",
    "    print(\"%s F1 Score Weighted: %.2f%%\" % (name,f1_weighted * 100.0)) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-sterling",
   "metadata": {},
   "source": [
    "#### Improving Multi-layer Perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "treated-pregnancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Net Activation function: identity F1 Score Micro: 51.75%\n",
      "Neural Net Activation function: identity F1 Score Macro: 11.78%\n",
      "Neural Net Activation function: identity F1 Score Weighted: 54.28%\n",
      "Neural Net Activation function: logistic F1 Score Micro: 70.18%\n",
      "Neural Net Activation function: logistic F1 Score Macro: 8.89%\n",
      "Neural Net Activation function: logistic F1 Score Weighted: 62.38%\n",
      "Neural Net Activation function: tanh F1 Score Micro: 54.39%\n",
      "Neural Net Activation function: tanh F1 Score Macro: 11.92%\n",
      "Neural Net Activation function: tanh F1 Score Weighted: 55.77%\n",
      "Neural Net Activation function: relu F1 Score Micro: 53.95%\n",
      "Neural Net Activation function: relu F1 Score Macro: 11.90%\n",
      "Neural Net Activation function: relu F1 Score Weighted: 55.50%\n"
     ]
    }
   ],
   "source": [
    "# activation functions:\n",
    "\n",
    "activation_functions=[\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "\n",
    "for i in activation_functions:\n",
    "    mlp_classifier = MLPClassifier(alpha=1, max_iter=5000, activation=i)\n",
    "    mlp_classifier.fit(train_X_processed, train_y)\n",
    "    y_pred = mlp_classifier.predict(val_X_processed)\n",
    "    \n",
    "    f1_micro = f1_score(val_y, y_pred, average=\"micro\")\n",
    "    f1_macro = f1_score(val_y, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(val_y, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(\"Neural Net Activation function: %s F1 Score Micro: %.2f%%\" % (i,f1_micro * 100.0))\n",
    "    print(\"Neural Net Activation function: %s F1 Score Macro: %.2f%%\" % (i,f1_macro * 100.0))\n",
    "    print(\"Neural Net Activation function: %s F1 Score Weighted: %.2f%%\" % (i,f1_weighted * 100.0)) \n",
    "\n",
    "# it does not seem to matter as much on f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "protective-prediction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Net Solver: lbfgs F1 Score Micro: 23.25%\n",
      "Neural Net Solver: lbfgs F1 Score Macro: 5.94%\n",
      "Neural Net Solver: lbfgs F1 Score Weighted: 32.74%\n",
      "Neural Net Solver: sgd F1 Score Micro: 70.18%\n",
      "Neural Net Solver: sgd F1 Score Macro: 9.16%\n",
      "Neural Net Solver: sgd F1 Score Weighted: 57.88%\n",
      "Neural Net Solver: adam F1 Score Micro: 70.18%\n",
      "Neural Net Solver: adam F1 Score Macro: 8.89%\n",
      "Neural Net Solver: adam F1 Score Weighted: 62.38%\n"
     ]
    }
   ],
   "source": [
    "solvers = [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "\n",
    "for i in solvers:\n",
    "    mlp_classifier = MLPClassifier(alpha=1, max_iter=5000, activation = \"logistic\", solver=i)\n",
    "    mlp_classifier.fit(train_X_processed, train_y)\n",
    "    y_pred = mlp_classifier.predict(val_X_processed)\n",
    "    \n",
    "    f1_micro = f1_score(val_y, y_pred, average=\"micro\")\n",
    "    f1_macro = f1_score(val_y, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(val_y, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(\"Neural Net Solver: %s F1 Score Micro: %.2f%%\" % (i,f1_micro * 100.0))\n",
    "    print(\"Neural Net Solver: %s F1 Score Macro: %.2f%%\" % (i,f1_macro * 100.0))\n",
    "    print(\"Neural Net Solver: %s F1 Score Weighted: %.2f%%\" % (i,f1_weighted * 100.0)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "processed-seven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Net L2 Penalty: 0.001 F1 Score Micro: 16.23%\n",
      "Neural Net L2 Penalty: 0.001 F1 Score Macro: 4.92%\n",
      "Neural Net L2 Penalty: 0.001 F1 Score Weighted: 24.11%\n",
      "Neural Net L2 Penalty: 0.01 F1 Score Micro: 14.47%\n",
      "Neural Net L2 Penalty: 0.01 F1 Score Macro: 4.79%\n",
      "Neural Net L2 Penalty: 0.01 F1 Score Weighted: 21.58%\n",
      "Neural Net L2 Penalty: 0.1 F1 Score Micro: 41.67%\n",
      "Neural Net L2 Penalty: 0.1 F1 Score Macro: 4.84%\n",
      "Neural Net L2 Penalty: 0.1 F1 Score Weighted: 49.98%\n",
      "Neural Net L2 Penalty: 1 F1 Score Micro: 70.18%\n",
      "Neural Net L2 Penalty: 1 F1 Score Macro: 8.89%\n",
      "Neural Net L2 Penalty: 1 F1 Score Weighted: 62.38%\n",
      "Neural Net L2 Penalty: 2 F1 Score Micro: 70.18%\n",
      "Neural Net L2 Penalty: 2 F1 Score Macro: 9.16%\n",
      "Neural Net L2 Penalty: 2 F1 Score Weighted: 57.88%\n",
      "Neural Net L2 Penalty: 5 F1 Score Micro: 70.18%\n",
      "Neural Net L2 Penalty: 5 F1 Score Macro: 9.16%\n",
      "Neural Net L2 Penalty: 5 F1 Score Weighted: 57.88%\n",
      "Neural Net L2 Penalty: 10 F1 Score Micro: 70.18%\n",
      "Neural Net L2 Penalty: 10 F1 Score Macro: 9.16%\n",
      "Neural Net L2 Penalty: 10 F1 Score Weighted: 57.88%\n"
     ]
    }
   ],
   "source": [
    "l2_penalties = [0.001, 0.01, 0.1, 1, 2, 5, 10]\n",
    "\n",
    "for i in l2_penalties:\n",
    "    mlp_classifier = MLPClassifier(solver='adam', alpha=i, max_iter=5000, activation=\"logistic\")\n",
    "    mlp_classifier.fit(train_X_processed, train_y)\n",
    "    y_pred = mlp_classifier.predict(val_X_processed)\n",
    "    \n",
    "    f1_micro = f1_score(val_y, y_pred, average=\"micro\")\n",
    "    f1_macro = f1_score(val_y, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(val_y, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(\"Neural Net L2 Penalty: %s F1 Score Micro: %.2f%%\" % (i,f1_micro * 100.0))\n",
    "    print(\"Neural Net L2 Penalty: %s F1 Score Macro: %.2f%%\" % (i,f1_macro * 100.0))\n",
    "    print(\"Neural Net L2 Penalty: %s F1 Score Weighted: %.2f%%\" % (i,f1_weighted * 100.0))\n",
    "    \n",
    "# keept it as 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "romantic-berry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Net Learning Rate Type: constant F1 Score Micro: 70.18%\n",
      "Neural Net Learning Rate Type: constant F1 Score Macro: 8.84%\n",
      "Neural Net Learning Rate Type: constant F1 Score Weighted: 62.03%\n",
      "Neural Net Learning Rate Type: invscaling F1 Score Micro: 70.18%\n",
      "Neural Net Learning Rate Type: invscaling F1 Score Macro: 8.86%\n",
      "Neural Net Learning Rate Type: invscaling F1 Score Weighted: 62.21%\n",
      "Neural Net Learning Rate Type: adaptive F1 Score Micro: 70.18%\n",
      "Neural Net Learning Rate Type: adaptive F1 Score Macro: 8.89%\n",
      "Neural Net Learning Rate Type: adaptive F1 Score Weighted: 62.38%\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "\n",
    "for i in learning_rates:\n",
    "    mlp_classifier = MLPClassifier(solver='adam', \n",
    "                                   alpha=1, \n",
    "                                   max_iter=5000, \n",
    "                                   activation='logistic', \n",
    "                                   learning_rate=i)\n",
    "    mlp_classifier.fit(train_X_processed, train_y)\n",
    "    y_pred = mlp_classifier.predict(val_X_processed)\n",
    "    \n",
    "    f1_micro = f1_score(val_y, y_pred, average=\"micro\")\n",
    "    f1_macro = f1_score(val_y, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(val_y, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(\"Neural Net Learning Rate Type: %s F1 Score Micro: %.2f%%\" % (i,f1_micro * 100.0))\n",
    "    print(\"Neural Net Learning Rate Type: %s F1 Score Macro: %.2f%%\" % (i,f1_macro * 100.0))\n",
    "    print(\"Neural Net Learning Rate Type: %s F1 Score Weighted: %.2f%%\" % (i,f1_weighted * 100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "requested-shannon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Net Initial Learning Rate: 0.001 F1 Score Micro: 70.18%\n",
      "Neural Net Initial Learning Rate: 0.001 F1 Score Macro: 8.84%\n",
      "Neural Net Initial Learning Rate: 0.001 F1 Score Weighted: 62.03%\n",
      "Neural Net Initial Learning Rate: 0.01 F1 Score Micro: 70.18%\n",
      "Neural Net Initial Learning Rate: 0.01 F1 Score Macro: 8.77%\n",
      "Neural Net Initial Learning Rate: 0.01 F1 Score Weighted: 61.52%\n",
      "Neural Net Initial Learning Rate: 0.1 F1 Score Micro: 70.18%\n",
      "Neural Net Initial Learning Rate: 0.1 F1 Score Macro: 8.53%\n",
      "Neural Net Initial Learning Rate: 0.1 F1 Score Weighted: 59.88%\n",
      "Neural Net Initial Learning Rate: 1 F1 Score Micro: 70.18%\n",
      "Neural Net Initial Learning Rate: 1 F1 Score Macro: 9.16%\n",
      "Neural Net Initial Learning Rate: 1 F1 Score Weighted: 57.88%\n",
      "Neural Net Initial Learning Rate: 2 F1 Score Micro: 70.18%\n",
      "Neural Net Initial Learning Rate: 2 F1 Score Macro: 9.16%\n",
      "Neural Net Initial Learning Rate: 2 F1 Score Weighted: 57.88%\n",
      "Neural Net Initial Learning Rate: 5 F1 Score Micro: 10.53%\n",
      "Neural Net Initial Learning Rate: 5 F1 Score Macro: 2.12%\n",
      "Neural Net Initial Learning Rate: 5 F1 Score Weighted: 2.01%\n",
      "Neural Net Initial Learning Rate: 10 F1 Score Micro: 70.18%\n",
      "Neural Net Initial Learning Rate: 10 F1 Score Macro: 9.16%\n",
      "Neural Net Initial Learning Rate: 10 F1 Score Weighted: 57.88%\n"
     ]
    }
   ],
   "source": [
    "learning_rate_inits = [0.001, 0.01, 0.1, 1, 2, 5, 10]\n",
    "\n",
    "\n",
    "for i in learning_rate_inits:\n",
    "    mlp_classifier = MLPClassifier(solver=\"adam\", \n",
    "                                   alpha=1, \n",
    "                                   max_iter=5000, \n",
    "                                   activation=\"logistic\",\n",
    "                                   learning_rate=\"adaptive\",\n",
    "                                   learning_rate_init=i)\n",
    "    mlp_classifier.fit(train_X_processed, train_y)\n",
    "    y_pred = mlp_classifier.predict(val_X_processed)\n",
    "    \n",
    "    f1_micro = f1_score(val_y, y_pred, average=\"micro\")\n",
    "    f1_macro = f1_score(val_y, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(val_y, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(\"Neural Net Initial Learning Rate: %s F1 Score Micro: %.2f%%\" % (i,f1_micro * 100.0))\n",
    "    print(\"Neural Net Initial Learning Rate: %s F1 Score Macro: %.2f%%\" % (i,f1_macro * 100.0))\n",
    "    print(\"Neural Net Initial Learning Rate: %s F1 Score Weighted: %.2f%%\" % (i,f1_weighted * 100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "multiple-twins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Net Learning Rate Type: 1000 F1 Score Micro: 70.18%\n",
      "Neural Net Learning Rate Type: 1000 F1 Score Macro: 8.79%\n",
      "Neural Net Learning Rate Type: 1000 F1 Score Weighted: 61.69%\n",
      "Neural Net Learning Rate Type: 5000 F1 Score Micro: 70.18%\n",
      "Neural Net Learning Rate Type: 5000 F1 Score Macro: 8.84%\n",
      "Neural Net Learning Rate Type: 5000 F1 Score Weighted: 62.03%\n",
      "Neural Net Learning Rate Type: 6000 F1 Score Micro: 70.18%\n",
      "Neural Net Learning Rate Type: 6000 F1 Score Macro: 8.77%\n",
      "Neural Net Learning Rate Type: 6000 F1 Score Weighted: 61.52%\n",
      "Neural Net Learning Rate Type: 7000 F1 Score Micro: 70.18%\n",
      "Neural Net Learning Rate Type: 7000 F1 Score Macro: 8.89%\n",
      "Neural Net Learning Rate Type: 7000 F1 Score Weighted: 62.38%\n"
     ]
    }
   ],
   "source": [
    "max_iters = [1000, 5000, 6000, 7000]\n",
    "\n",
    "for i in max_iters:\n",
    "    mlp_classifier = MLPClassifier(solver='adam', \n",
    "                                   alpha=1, \n",
    "                                   max_iter=i, \n",
    "                                   activation='logistic', \n",
    "                                   learning_rate='adaptive', \n",
    "                                   learning_rate_init=0.001)\n",
    "    mlp_classifier.fit(train_X_processed, train_y)\n",
    "    y_pred = mlp_classifier.predict(val_X_processed)\n",
    "    \n",
    "    f1_micro = f1_score(val_y, y_pred, average=\"micro\")\n",
    "    f1_macro = f1_score(val_y, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(val_y, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(\"Neural Net Learning Rate Type: %s F1 Score Micro: %.2f%%\" % (i,f1_micro * 100.0))\n",
    "    print(\"Neural Net Learning Rate Type: %s F1 Score Macro: %.2f%%\" % (i,f1_macro * 100.0))\n",
    "    print(\"Neural Net Learning Rate Type: %s F1 Score Weighted: %.2f%%\" % (i,f1_weighted * 100.0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-olive",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "bacterial-november",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:49:54] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Voting Classifier F1 Score Micro: 70.18%\n",
      "Voting Classifier F1 Score Macro: 8.77%\n",
      "Voting Classifier F1 Score Weighted: 61.52%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "name = \"Voting Classifier\"\n",
    "\n",
    "clf1 = MLPClassifier(solver='adam', \n",
    "                     alpha=1, \n",
    "                     max_iter=7000, \n",
    "                     activation='logistic', \n",
    "                     learning_rate='adaptive', \n",
    "                     learning_rate_init=0.001)\n",
    "\n",
    "clf2 = RandomForestClassifier(max_depth=5, \n",
    "                              n_estimators=500, \n",
    "                              max_features=10, \n",
    "                              criterion='gini', \n",
    "                              bootstrap=False)\n",
    "\n",
    "clf3 = xgb.XGBClassifier(learning_rate=0.01, \n",
    "                         booster = 'gblinear', \n",
    "                         reg_lambda=0.01,\n",
    "                         reg_alpha=0.001,\n",
    "                         objective='multi:softmax')\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('mlp', clf1), ('rfc', clf2), ('xgb', clf3)], \n",
    "                         voting='hard')\n",
    "\n",
    "eclf1.fit(train_X_processed, xgb_train_y)\n",
    "y_pred = eclf1.predict(val_X_processed)\n",
    "\n",
    "f1_micro = f1_score(xgb_val_y, y_pred, average=\"micro\")\n",
    "f1_macro = f1_score(xgb_val_y, y_pred, average=\"macro\")\n",
    "f1_weighted = f1_score(xgb_val_y, y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"%s F1 Score Micro: %.2f%%\" % (name,f1_micro * 100.0))\n",
    "print(\"%s F1 Score Macro: %.2f%%\" % (name,f1_macro * 100.0))\n",
    "print(\"%s F1 Score Weighted: %.2f%%\" % (name,f1_weighted * 100.0)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-species",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bored-incident",
   "metadata": {},
   "source": [
    "### DistilBERT for Sentence Embeddings + Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "civil-willow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>urology</td>\n",
       "      <td>inguinal hernia direct inguinal hernia rutkow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>urology</td>\n",
       "      <td>inguinal herniorrhaphy after informed consent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>urology</td>\n",
       "      <td>bilateral inguinal hernia bilateral inguinal h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   medical_specialty                                      transcription\n",
       "95           urology  inguinal hernia direct inguinal hernia rutkow ...\n",
       "96           urology  inguinal herniorrhaphy after informed consent ...\n",
       "97           urology  bilateral inguinal hernia bilateral inguinal h..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tr[95:98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "canadian-bidding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allergy immunology</td>\n",
       "      <td>this year old white female presents with compl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bariatrics</td>\n",
       "      <td>he has difficulty climbing stairs difficulty w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    medical_specialty                                      transcription\n",
       "0  allergy immunology  this year old white female presents with compl...\n",
       "1          bariatrics  he has difficulty climbing stairs difficulty w..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tr.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "proved-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel,DistilBertTokenizer, DistilBertConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "synthetic-sender",
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = DistilBertConfig(max_position_embeddings=4000, dropout=0.5, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "textile-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBertModel(configuration).from_pretrained('distilbert-base-uncased')\n",
    "tokenizer = DistilBertTokenizer(configuration).from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "necessary-indian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [101, 2023, 2095, 2214, 2317, 2931, 7534, 2007...\n",
       "1       [101, 2002, 2038, 7669, 8218, 5108, 7669, 2007...\n",
       "2       [101, 1045, 2031, 2464, 2651, 2002, 2003, 1037...\n",
       "3       [101, 1040, 1049, 2187, 2012, 14482, 4372, 801...\n",
       "4       [101, 1996, 2187, 18834, 7277, 7934, 17790, 29...\n",
       "                              ...                        \n",
       "4961    [101, 1045, 2018, 1996, 5165, 1997, 3116, 1998...\n",
       "4962    [101, 27324, 4295, 27324, 4295, 29304, 2023, 2...\n",
       "4963    [101, 2023, 2003, 1037, 2095, 2214, 2317, 2931...\n",
       "4964    [101, 2023, 2095, 2214, 3287, 7534, 2000, 2336...\n",
       "4965    [101, 1037, 2095, 2214, 3287, 7534, 2651, 2969...\n",
       "Name: transcription, Length: 4966, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_transcripts = data_tr['transcription'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=100))\n",
    "tokenized_transcripts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "simple-dinner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       100\n",
       "1       100\n",
       "2       100\n",
       "3        96\n",
       "4       100\n",
       "       ... \n",
       "4961    100\n",
       "4962    100\n",
       "4963    100\n",
       "4964    100\n",
       "4965    100\n",
       "Name: transcription, Length: 4966, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make all sentences equal size for DistilBERT\n",
    "tokenized_transcripts.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "premium-employer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "present-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to make all the vectors the same size by padding shorter sentences with the token id 0. \n",
    "# You can refer to the notebook for the padding step, it’s basic python string and array manipulation.\n",
    "\n",
    "max_length = max(tokenized_transcripts.apply(len))\n",
    "\n",
    "padded_transcripts = [row+[0]*(max_length-len(row)) for row in tokenized_transcripts]\n",
    "padded_transcripts = np.array(padded_transcripts)\n",
    "\n",
    "#for row in tokenized_transcripts:\n",
    "    #if len(row) < max_length:\n",
    "        #difference = max_length - len(row)\n",
    "        #row.extend([0 for i in range(difference)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "practical-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masked_transcripts = np.where(padded_transcripts!=0,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abstract-stamp",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  2023,  2095, ..., 19077, 12509,   102],\n",
       "       [  101,  2002,  2038, ...,  2055,  2702,   102],\n",
       "       [  101,  1045,  2031, ...,  2009,  1998,   102],\n",
       "       ...,\n",
       "       [  101,  2023,  2003, ...,  3366,  2029,   102],\n",
       "       [  101,  2023,  2095, ...,  2091,  2000,   102],\n",
       "       [  101,  1037,  2095, ...,  1998,  5845,   102]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "oriented-journalism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_masked_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ultimate-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the matrix to input tensor for DistilBERT\n",
    "\n",
    "input_ids = torch.tensor(padded_transcripts)\n",
    "attention_masked = torch.tensor(attention_masked_transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "alleged-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_masked)\n",
    "    \n",
    "# last_hidden_states holds the outputs of DistilBERT. \n",
    "# It is a tuple with the shape \n",
    "# (number of examples, max number of tokens in the sequence, number of hidden units in the DistilBERT model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "imperial-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we’re only only interested in BERT’s output for the [CLS] token, \n",
    "# so we select that slice of the cube and discard everything else.\n",
    "\n",
    "# Slice the output for the first position for all the sequences, take all hidden unit outputs\n",
    "\n",
    "features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "concrete-arrow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['orthopedic', 'surgery', 'surgery', ..., 'chart progress notes',\n",
       "       'cardiovascular pulmonary', 'surgery'], dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split here\n",
    "y_val_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "practical-cleaner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3476, 768), (745, 768), (745, 768))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, train_size=0.7, random_state=42)\n",
    "labels = data_tr['medical_specialty'].values\n",
    "for train_index, val_test_index in sss.split(features, labels):\n",
    "    features_train, features_val_test = features[train_index], features[val_test_index]\n",
    "    y_train, y_val_test = labels[train_index], labels[val_test_index]\n",
    "    \n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, train_size=0.5, random_state=42)\n",
    "for val_index, test_index in sss.split(features_val_test, y_val_test):\n",
    "    features_val, features_test = features_val_test[val_index], features_val_test[test_index]\n",
    "    y_val, y_test = y_val_test[val_index], y_val_test[test_index]\n",
    "\n",
    "\n",
    "features_train.shape, features_val.shape, features_test.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "arranged-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train the Model using Logistic Regression()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ranking-singapore",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22281879194630871"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(max_iter=500)\n",
    "lr_clf.fit(features_train, y_train)\n",
    "\n",
    "lr_clf.score(features_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate on Validation Set using F-1 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "obvious-unknown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression F1 Score Micro: 28.59%\n",
      "logistic regression F1 Score Macro: 12.65%\n",
      "logistic regression F1 Score Weighted: 26.10%\n"
     ]
    }
   ],
   "source": [
    "name=\"logistic regression\"\n",
    "y_pred = lr_clf.predict(features_val)\n",
    "f1_micro = f1_score(y_val, y_pred, average=\"micro\")\n",
    "f1_macro = f1_score(y_val, y_pred, average=\"macro\")\n",
    "f1_weighted = f1_score(y_val, y_pred, average=\"weighted\")\n",
    "    \n",
    "print(\"%s F1 Score Micro: %.2f%%\" % (name,f1_micro * 100.0))\n",
    "print(\"%s F1 Score Macro: %.2f%%\" % (name,f1_macro * 100.0))\n",
    "print(\"%s F1 Score Weighted: %.2f%%\" % (name,f1_weighted * 100.0))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-starter",
   "metadata": {},
   "source": [
    "### Keras LSTM with Keras Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dynamic-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "christian-landing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allergy immunology</td>\n",
       "      <td>this year old white female presents with compl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bariatrics</td>\n",
       "      <td>he has difficulty climbing stairs difficulty w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    medical_specialty                                      transcription\n",
       "0  allergy immunology  this year old white female presents with compl...\n",
       "1          bariatrics  he has difficulty climbing stairs difficulty w..."
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tr.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "unlike-purse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription</th>\n",
       "      <th>specialty_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allergy immunology</td>\n",
       "      <td>this year old white female presents with compl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bariatrics</td>\n",
       "      <td>he has difficulty climbing stairs difficulty w...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bariatrics</td>\n",
       "      <td>i have seen today he is a very pleasant gentle...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    medical_specialty                                      transcription  \\\n",
       "0  allergy immunology  this year old white female presents with compl...   \n",
       "1          bariatrics  he has difficulty climbing stairs difficulty w...   \n",
       "2          bariatrics  i have seen today he is a very pleasant gentle...   \n",
       "\n",
       "   specialty_id  \n",
       "0             0  \n",
       "1             2  \n",
       "2             2  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tr3 = data_tr.copy()\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data_tr3['medical_specialty'].to_list())\n",
    "data_tr3['specialty_id'] = le.transform(data_tr3['medical_specialty'].to_list())\n",
    "data_tr3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "sticky-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_y.to_list())\n",
    "train_y_labels = le.transform(train_y.to_list())\n",
    "val_y_labels = le.transform(val_y.to_list())\n",
    "test_y_labels = le.transform(test_y.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "interracial-assumption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  3,  2,  3,  3,  2,  3,  2, 15])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fantastic-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "texts = data_tr3['transcription']\n",
    "tokenized_texts = [row.split() for row in texts]\n",
    "vocabulary = Counter()\n",
    "\n",
    "for row in tokenized_texts:\n",
    "    vocabulary.update(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "built-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocabulary)\n",
    "tokenizer = Tokenizer(num_words=vocab_size, split=' ', char_level=False)\n",
    "tokenizer.fit_on_texts(data_tr3['transcription'])\n",
    "\n",
    "tokenized_train_X = tokenizer.texts_to_sequences(train_X)\n",
    "tokenized_val_X = tokenizer.texts_to_sequences(val_X) \n",
    "tokenized_test_X = tokenizer.texts_to_sequences(test_X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "moral-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(x.split()) for x in data_tr3['transcription']])\n",
    "\n",
    "x_train = pad_sequences(tokenized_train_X, padding='post', maxlen=max_len)\n",
    "x_val = pad_sequences(tokenized_val_X, padding='post', maxlen=max_len)\n",
    "x_test = pad_sequences(tokenized_test_X, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "accompanied-league",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3476, 2991), (228, 2991))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "cross-clearance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 2991, 20)          442320    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                14200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 40)                2040      \n",
      "=================================================================\n",
      "Total params: 458,560\n",
      "Trainable params: 458,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size,\n",
    "                           output_dim=embedding_dim,\n",
    "                           input_length=max_len))\n",
    "model.add(layers.LSTM(units=50))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(len(specialties), activation=\"relu\"))\n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "instrumental-violence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "109/109 [==============================] - 103s 936ms/step - loss: 6.7775 - accuracy: 0.1114\n",
      "Epoch 2/20\n",
      "109/109 [==============================] - 92s 845ms/step - loss: 4.8344 - accuracy: 0.1775\n",
      "Epoch 3/20\n",
      "109/109 [==============================] - 92s 845ms/step - loss: 4.3802 - accuracy: 0.2189\n",
      "Epoch 4/20\n",
      "109/109 [==============================] - 92s 846ms/step - loss: 4.4413 - accuracy: 0.2213\n",
      "Epoch 5/20\n",
      "109/109 [==============================] - 92s 844ms/step - loss: 4.1789 - accuracy: 0.2131\n",
      "Epoch 6/20\n",
      "109/109 [==============================] - 92s 847ms/step - loss: 3.7896 - accuracy: 0.2283\n",
      "Epoch 7/20\n",
      "109/109 [==============================] - 93s 852ms/step - loss: 3.7890 - accuracy: 0.2224\n",
      "Epoch 8/20\n",
      "109/109 [==============================] - 93s 849ms/step - loss: 3.8774 - accuracy: 0.2172\n",
      "Epoch 9/20\n",
      "109/109 [==============================] - 93s 850ms/step - loss: 4.1748 - accuracy: 0.2101\n",
      "Epoch 10/20\n",
      "109/109 [==============================] - 93s 850ms/step - loss: 3.9877 - accuracy: 0.2241\n",
      "Epoch 11/20\n",
      "109/109 [==============================] - 92s 845ms/step - loss: 3.8845 - accuracy: 0.2306\n",
      "Epoch 12/20\n",
      "109/109 [==============================] - 93s 849ms/step - loss: 3.8108 - accuracy: 0.2248\n",
      "Epoch 13/20\n",
      "109/109 [==============================] - 92s 845ms/step - loss: 3.9673 - accuracy: 0.2116\n",
      "Epoch 14/20\n",
      "109/109 [==============================] - 92s 847ms/step - loss: 3.8273 - accuracy: 0.2307\n",
      "Epoch 15/20\n",
      "109/109 [==============================] - 92s 845ms/step - loss: 3.7757 - accuracy: 0.2170\n",
      "Epoch 16/20\n",
      "109/109 [==============================] - 92s 845ms/step - loss: 3.8150 - accuracy: 0.2262\n",
      "Epoch 17/20\n",
      "109/109 [==============================] - 96s 879ms/step - loss: 3.7135 - accuracy: 0.2197\n",
      "Epoch 18/20\n",
      "109/109 [==============================] - 100s 918ms/step - loss: 3.7580 - accuracy: 0.2209\n",
      "Epoch 19/20\n",
      "109/109 [==============================] - 99s 905ms/step - loss: 3.7182 - accuracy: 0.2121\n",
      "Epoch 20/20\n",
      "109/109 [==============================] - 94s 863ms/step - loss: 3.8246 - accuracy: 0.2184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f81a99846d0>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, train_y_labels , epochs=20, batch_size=32, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "received-commons",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessjkim/miniconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "       37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "       37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "       37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "       37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "       37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "       37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "       37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "       37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "       37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "       37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "       37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "       37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "       37, 37, 37, 37, 37, 37, 37])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "incoming-pierce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras LSTM F1 Score Micro: 70.18%\n",
      "Keras LSTM F1 Score Macro: 9.16%\n",
      "Keras LSTM F1 Score Weighted: 57.88%\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(x_val), axis=-1)\n",
    "name = \"Keras LSTM\"\n",
    "f1_micro = f1_score(val_y_labels, y_pred, average=\"micro\")\n",
    "f1_macro = f1_score(val_y_labels, y_pred, average=\"macro\")\n",
    "f1_weighted = f1_score(val_y_labels, y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"%s F1 Score Micro: %.2f%%\" % (name,f1_micro * 100.0))\n",
    "print(\"%s F1 Score Macro: %.2f%%\" % (name,f1_macro * 100.0))\n",
    "print(\"%s F1 Score Weighted: %.2f%%\" % (name,f1_weighted * 100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-blocking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bright-portsmouth",
   "metadata": {},
   "source": [
    "### Evaluating on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "sonic-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpclassifier = MLPClassifier(solver='adam', \n",
    "                     alpha=1, \n",
    "                     max_iter=7000, \n",
    "                     activation='logistic', \n",
    "                     learning_rate='adaptive', \n",
    "                     learning_rate_init=0.001)\n",
    "\n",
    "mlpclassifier.fit(train_X_processed, train_y)\n",
    "y_pred = mlpclassifier.predict(test_X_processed)\n",
    "\n",
    "f1_micro = f1_score(test_y, y_pred, average=\"micro\")\n",
    "f1_macro = f1_score(test_y, y_pred, average=\"macro\")\n",
    "f1_weighted = f1_score(test_y, y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "expected-remedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier on Test Set F1 Score Micro: 75.80%\n",
      "MLP Classifier on Test Set F1 Score Macro: 8.31%\n",
      "MLP Classifier on Test Set F1 Score Weighted: 69.33%\n"
     ]
    }
   ],
   "source": [
    "name = \"MLP Classifier on Test Set\"\n",
    "\n",
    "print(\"%s F1 Score Micro: %.2f%%\" % (name,f1_micro * 100.0))\n",
    "print(\"%s F1 Score Macro: %.2f%%\" % (name,f1_macro * 100.0))\n",
    "print(\"%s F1 Score Weighted: %.2f%%\" % (name,f1_weighted * 100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-orlando",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
